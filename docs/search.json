[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Programming for the Social Sciences Using R",
    "section": "",
    "text": "Preface\nWelcome! This is the companion website for Statistical Programming for the Social Sciences Using R, taught at the Sciences Po Reims campus in the Spring 2024 term. The course is a broad introduction to the general programming skills required for data analysis in the social sciences.\nThis online textbook contains the relevant tutorials for each week’s lesson as well as other resources that you may find helpful throughout the course. The syllabus, slides, assignment submission portals, and other files can be found on the course Moodle site."
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Statistical Programming for the Social Sciences Using R",
    "section": "Resources",
    "text": "Resources\nThere are a variety of R resources out there, many of which have been useful in developing this course.\nIf you would like to dig deeper into a particular topic or simply want to read other explanations of the concepts discussed in this course, here is a list of helpful resources:\n\nR for Data Science, 2e by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund (link): A free introductory textbook on how to use the many features of R to make sense of data, co-authored by the creator of the tidyverse package.\nData Visualization by Kieran Healy (draft textbook): An introductory textbook on how to make practical and beautiful data visualizations in R. Healy has a distinctive and appealing visual style. He also happens to be an accomplished sociologist, known especially for his disdain of nuanced theory and his broader contributions to the study of morals and markets. His examples are especially relevant to the social sciences as a result.\nIntroduction to Econometrics with R by Florian Oswald and colleagues at Sciences Po (companion textbook and slides): you may very well be taking this course because you couldn’t get into this other course. For this, I am both sorry, because you are missing out, and not sorry, because it keeps me gainfully employed and gives me an excuse to write this textbook. Fortunately for you, the course developed by Professor Oswald and colleagues is freely-available online. If you’d like to see material which is more heavily-weighted towards applied statistical methods (especially applied economics), take a look at their extremely well put together course. You may very well rue the day you woke up late for course sign-ups.\nggplot2: Elegant Graphics for Data Analysis (3e) by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen (link): An in-depth explanation of how the popular ggplot2 data visualization package works."
  },
  {
    "objectID": "index.html#change-log",
    "href": "index.html#change-log",
    "title": "Statistical Programming for the Social Sciences Using R",
    "section": "Change Log",
    "text": "Change Log\nI’ll be making frequent updates to the textbook, often changing the appearance, structure, and/or content. In general, these changes won’t be substantive. In other words, they won’t change what you are required to know or how you are expected to do things. You might, however, find that certain sections become more detailed as the course progresses. If you would like to see a detailed list of changes (including my frequent struggles with word choice), take a look at the GitHub repository. For those of you with better things to do in your spare time, a brief chronological summary of updates is provided below:\n\n2024.02.25 - Chapter 4 has been posted.\n2024.02.22 - Another resource added to the preface. Minor copy edits.\n2024.02.18 - I’ve refactored the course website from R Markdown to Quarto. You may notice some significant changes to the appearance of the website, including the appearance of a new navigation bar on the right-hand side (used for navigating sections within a chapter) and changes to the standard navigation bar on the left-hand side (no more sections and subsections). I’m not completely in love this specific change, but the other benefits of switching to Quarto are worth it (more functionality, better visual appeal in other areas). Links have been updated as a result (apologies to those of you who may have bookmarked sections). Also, a technical note has been added to Homework #2 (it will not affect the grading of relevant questions)."
  },
  {
    "objectID": "intro-to-r.html#installing-r",
    "href": "intro-to-r.html#installing-r",
    "title": "1  An Introduction to R",
    "section": "1.1 Installing R",
    "text": "1.1 Installing R\nTo install R, go to https://cran.irsn.fr/index.html, select the appropriate operating system, and follow the instructions. For example, if you have a Mac, you will click on “Download R for macOS,” followed by the “R-4.3.2-arm64.pkg” link beneath the “Latest release” header. If you have a PC running Windows, you will click on “Download R for Windows” followed by “install R for the first time” then “Download R-4.3.2 for Windows.”\nIn either case, your browser will start downloading an executable installation file which you will then need to run to install R.\n\n\n\n\n\n\nCaution\n\n\n\nA couple of things you may need to watch out for:\n\nIf you are using an older laptop (&gt;10 years old), you may need to download a different version of R or RStudio. If in doubt, read the instructions on the download page and refer to your operating system version to find the right version.\nIf you have very little hard drive space on your computer, you may need to clear some space before you install RStudio. The latest RStudio version requires 215 MB and you will likely need some additional space for other software and data we will be using in the course later on. Around 2 GB should suffice."
  },
  {
    "objectID": "intro-to-r.html#installing-rstudio",
    "href": "intro-to-r.html#installing-rstudio",
    "title": "1  An Introduction to R",
    "section": "1.2 Installing RStudio",
    "text": "1.2 Installing RStudio\nOnce you’ve installed R, go to https://posit.co/download/rstudio-desktop/.\nPosit (a company formerly known as RStudio) offers RStudio Desktop free of charge. Posit also offers a cloud-hosted version of the software (called Posit Cloud) which has both free and paid tiers. If you have trouble running RStudio Desktop on your computer, you may wish to consider using a Posit Cloud account, as described in the course syllabus.\nWhen you’ve click on the link above, you’ll find that you are ahead of the game. Step 1 is complete, you’ve already installed R. Here you’ll find different versions of RStudio according to your computer’s operating system. Select the operating system that corresponds to your particular case (Windows, MacOS, or Linux), download the installer, and then run the installation file from your computer. Next, follow the on-screen steps to complete the set-up.\nIf all goes well, your screen should look something like this once you have RStudio correctly installed and running:\n\nIf your screen looks more like the image below, it means that you’ve accidentally opened RGui, a basic graphical user interface included with R, and not RStudio. We’re always going to be working with RStudio for this class, so close out of RGui and open RStudio instead."
  },
  {
    "objectID": "intro-to-r.html#using-the-console",
    "href": "intro-to-r.html#using-the-console",
    "title": "1  An Introduction to R",
    "section": "1.3 Using the Console",
    "text": "1.3 Using the Console\nNow the fun begins. The RStudio window you’ve opened consists of a few different parts. The most important of these right now is the console pane (highlighted with a black square below).\n\nThe console allows you to interact with your computer using R. So, for example, if you want to use your computer as an over-sized calculator, you can type the following R code in the console:\n1 + 1\nWhat happens when you press Enter on your keyboard? You get something like this:\n\n1 + 1\n\n[1] 2\n\n\nYou’ve provided an input, 1+1, and received an output, 2. In other words, using the language of R, you’ve told your computer to add one plus one and your computer has correctly interpreted your command and returned (or output) an answer, two. When your computer does not know how to interpret a command, usually because you’ve made a mistake, you will receive an error message as the output instead. Identifying errors and being able to correct them is an essential skill for a programmer and one we will practice, often accidentally, throughout the course.\nOne more note about outputs: the first number in brackets next to your output, [1], indicates the index number of the output.1 This is especially helpful when you are running code that generates multiple outputs. See below, for example, where we input LETTERS and receive a list of letters in the English alphabet as the output (note, “T” is the 20th letter and our 20th output).\n\nLETTERS\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\nTry entering a few more inputs in the console:\n\n10/3\n(10/3) + 1\n(10/3) + 1 + (5.111)\\^2\n\nAs you can see, R is able to handle basic math operations with ease. What about other operations? Can you work with variables in R, for example?\nTry typing this in the console:\n\nx = 1\n\nWhat happens when you press Enter?\n\nUnlike before, there is no output when you press Enter. But, that doesn’t mean nothing happened. In fact, something has happened. You’ve stored a value, 1, in a variable, x, somewhere in your computer’s memory or in what we might call the environment. You don’t receive an output, but RStudio reminds you of your new object’s existence via the environment pane in the top right.\nWe can recall the value we input into our variable, x, by entering the object name in the console:\n\nx\n\n[1] 1\n\n\nSee! Your computer remembers what you stored in the environment.\nTry the following on your own in the console and then take a look at the answer:\n\nCan you assign a new value to your variable, x?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes!\n\nx = 3\nx\n\n[1] 3\n\n\n\n\n\nCan you perform math operations on a variable (e.g., x*5)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes!\n\nx * 5\n\n[1] 15\n\n\n\n\n\nCan you create a new variable, y, and use it in math operations with x (e.g., x * y)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes!\n\ny = 2\nx * y\n\n[1] 6\n\n\n\n\n\nCan you change the type of variable? What if, for example, I want x to be equal to the word \"apple\" instead?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes! For letters and words, you just have to use quotation marks:\n\nx = \"apple\"\nx\n\n[1] \"apple\""
  },
  {
    "objectID": "intro-to-r.html#calculations-with-objects",
    "href": "intro-to-r.html#calculations-with-objects",
    "title": "1  An Introduction to R",
    "section": "1.4 Calculations with Objects",
    "text": "1.4 Calculations with Objects\nIf you’ve made it this far, well done! Here’s something else you can try. Enter the following in the console:\n\nx &lt;- c(1, 2, 3, 4, 5)\n\nYou’ll notice that we’re using a different operator here. It’s a less than symbol, &lt;, followed by a dash, -. This is called an assignment operator and it has the same function as the equals sign, =. You can use either, but sticking with &lt;- when assigning values to objects will make life easier later on.\nWhat happens when you press Enter? You have created a vector. In R, a vector is an object that holds a set of values of the same type. In this case, the vector x contains a set of numbers: \\(\\{1,2,3,4,5\\}\\). You can think of an object as a container which holds things and a “variable” as the name we use to refer to a specific object. Here, x is the variable name we’ve given to our vector of numbers, which is an object. Most things in R are objects.\nWe can do all sorts of things with vectors and other objects in R. We can, for example, find the sum of a vector.\n\nsum(x)\n\n[1] 15\n\n\nHow did we get an output of 15? We summed each of the elements of our vector x: \\(1+2+3+4+5 = 15\\). We can also find the mean of a vector:\n\nmean(x)\n\n[1] 3\n\n\nAnd, we can perform other operations on vectors too. Try each of the following questions on your own in the console and then click on the answer to check your work:\n\nCan you find the median of a vector?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou can use median() instead of mean()!\n\nmedian(x)\n\n[1] 3\n\n\nSome functions are easy to guess, like median(), but others are false cognates just like in human languages (e.g., mode() won’t get you what you might expect in R and asking for pain in English won’t get you bread). We’ll talk more about functions and how to figure out what they do in the next chapter.\n\n\n\nWhat happens when you multiply a vector by a number?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nEach value in the vector is multiplied by that number!\n\nx * 2\n\n[1]  2  4  6  8 10\n\n\n\n\n\nCan you create a new vector which consists only of letters? What about words?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes! Instead of using numbers, you can create a vector using letters enclosed in quotation marks.\n\ny &lt;- c('a', 'b', 'c')\ny\n\n[1] \"a\" \"b\" \"c\"\n\n\nThe same works for words:\n\ny &lt;- c('cat', 'dog', 'parakeet')\ny\n\n[1] \"cat\"      \"dog\"      \"parakeet\""
  },
  {
    "objectID": "intro-to-r.html#saving-your-work",
    "href": "intro-to-r.html#saving-your-work",
    "title": "1  An Introduction to R",
    "section": "1.5 Saving Your Work",
    "text": "1.5 Saving Your Work\nAs you’ve started to see, working with a scripting language like R is quite different from working with software like Microsoft Excel or Google Sheets. You work interactively with data using code rather than by changing values directly in a user interface. No more clicking on cells to change values, now you change them programmatically.\nOne of the great advantages of interacting with data in this way, particularly for the social sciences, is that it allows us to see all of the steps you’ve taken to produce your analysis and repeat them. We don’t have to take your word for how you’ve calculated something. We can see the code and use it ourselves to produce the same thing.\nThis means that we leave our source data alone and write the code that produces the analysis. As with any good recipe, we want the code you write to be clear and easy to follow so that anyone can come back to it and understand what you did. We’ll say more about how to do this later on.\nThere are a couple of different ways to save your code:\n\nIn an R Script, a simple text file ending in a .r extension\nIn an R Markdown file, an interactive format that allows you to see your code and the results together in the same file\n\nWe’re going to start with an R Script file and try out R Markdown later on."
  },
  {
    "objectID": "intro-to-r.html#creating-and-saving-an-r-script",
    "href": "intro-to-r.html#creating-and-saving-an-r-script",
    "title": "1  An Introduction to R",
    "section": "1.6 Creating and Saving an R Script",
    "text": "1.6 Creating and Saving an R Script\nTo create an R Script file in RStudio, go to File &gt; New File &gt; R Script.\n\nYou should now have a window open in RStudio which looks like this:\n\nYou can enter comments in your R Script file using a hash tag (#) at the beginning of each comment line. A hash tag lets R know that this line should not be run as code. Its purpose is to tell us what is happening in a particular section of the code.\nI like to start by adding my name, the date, and a description to each file I use. I’ll ask that you use a header for each R file you submit for this class as well.\n\nNow, save your R Script somewhere on your computer. Go to File &gt; Save As, then choose a safe place to store it (I recommend creating a folder for this course), give your file a name, and press save. I called mine “hello_world”."
  },
  {
    "objectID": "intro-to-r.html#interacting-in-an-r-script",
    "href": "intro-to-r.html#interacting-in-an-r-script",
    "title": "1  An Introduction to R",
    "section": "1.7 Interacting in an R Script",
    "text": "1.7 Interacting in an R Script\nInteracting in an R Script is slightly different from interacting with the console. Now when you type in code and hit Enter, it will not execute the code, it just creates a new line in your file.\nTo run code in a script in RStudio, you can either:\n\nSelect the lines you wish to run with your cursor and then press Ctrl + Enter\nOr, put your cursor on the line you wish to run and click the Run button in the upper-right of the R Script pane\n\n\nThe first option allows you to run multiple lines at a time. The second runs only the line you are currently on. The results of your code will appear in the console pane below your R Script file when run successfully.\nAfter you finish modifying your R Script file, you can save it and close out of RStudio. The next time you wish to access your saved code, you can open your R Script file and your code will be exactly as you left it."
  },
  {
    "objectID": "intro-to-r.html#summary",
    "href": "intro-to-r.html#summary",
    "title": "1  An Introduction to R",
    "section": "1.8 Summary",
    "text": "1.8 Summary\nLet’s briefly recap what you learned this lesson. So far you’ve learned:\n\nThe difference between R and RStudio\nHow to interact with the console\nHow to create and store values in objects using an assignment operator\nWhat a vector is and how to create one\nHow to use basic functions like sum() and mean() to perform calculations\nHow to make comments using the # symbol\nHow to create and save R Script files"
  },
  {
    "objectID": "intro-to-r.html#footnotes",
    "href": "intro-to-r.html#footnotes",
    "title": "1  An Introduction to R",
    "section": "",
    "text": "In R, unlike in other programming languages, the first value in any data structure (e.g., a vector) has an index number of 1 rather than 0. This makes intuitive sense. If you were asked to count people in line at a boulangerie, you would call the next person waiting to place their order the first person in line, not the zeroeth. In Python, you would call them the zeroeth person and they would have an index number of 0 instead of 1. For more on where this comes from, see here.↩︎"
  },
  {
    "objectID": "working-with-data-in-r.html#functions",
    "href": "working-with-data-in-r.html#functions",
    "title": "2  Working with Data in R",
    "section": "2.1 Functions",
    "text": "2.1 Functions\nLast class, we assigned a vector to a variable like this:\n\nmy_vector &lt;- c(1, 2, 3, 4, 5, 6)\n\nWhere my_vector is an object and \\({1,2,3,4,5,6}\\) is the set of values assigned to it. When you run this code in your console (or in a script file), your new variable and its assigned values are stored in short-term memory and appear in the Environment pane of RStudio.\nWhen we assigned a single value to another variable, however, as in:\n\nx &lt;- 1\n\nor,\n\nfirst_name = 'Wesley'\n\nwe didn’t use c(). So, what exactly is c()?\nLike sum() or mean(), c() is a function. Functions play an important role in all programming languages. They are snippets of code, often hidden in the background, that allow us to accomplish specific tasks, like adding up all of the numbers in a vector, taking the mean, or creating a vector. In R, c() is a function which combines values into a vector or list.\nFunctions give us the ability to recall previously written code to perform the same task over again. Why re-write code every time you need to use it, after all, when you could use the same code you used last time? Instead of copying and pasting code, we can put it in a function, save it somewhere, and call it when we need it.\n\n2.1.1 Calling a Function\nWhen we want to use a function, or ‘call’ it as we will sometimes say, we type in the name of the function, enclose arguments in a set of parentheses, and run the command. The general form looks something like this:\nfunction([arg1], [arg2], ...)\n\n\n2.1.2 Using Arguments in a Function\nIn some cases, you may just have one argument for a function, as when you want to use the sum() function to add the elements of a vector:\n\nsum(my_vector)\n\n[1] 21\n\n\nIn other cases, you may have multiple arguments:\n\nsum(my_vector, my_vector)\n\n[1] 42\n\n\nArguments can be required or optional and the number of arguments and the order in which they are input depends on the specific function you are using and what you are trying to accomplish. The sum() function, for instance, returns the sum of all values given as arguments.\nArguments can also be used to specify options for a function. Take a look at the example below:\n\nsum(my_vector, NA, my_vector)\n\n[1] NA\n\n\nHere we are using the sum() function to add my_vector twice, as in the previous example, but now with a missing value (NA). Because the sum of two vectors plus a missing value is unknown, we get an unknown value (NA) as the output.\nIf we want the sum() function to ignore the unknown value, we have to provide it with an additional, named argument which tells it to ignore NA. We can specify this by adding , na.rm = TRUE to our function call. See what happens below:\n\nsum(my_vector, NA, my_vector, na.rm = TRUE)\n\n[1] 42\n\n\nWe’re back to an answer of 42. The sum() function ignored the missing value, as we specified, and added the two vectors.\nAll functions have named arguments and an ordering to them. If you omit the name of an argument in your function call, the function processes them according to their default ordering. It is generally a good habit to specify argument names, as in the example below where the ‘x’ argument in the sum() function takes the object you are trying to sum, but it is not entirely necessary for simple functions.\n\nsum(x = my_vector)\n\n[1] 21\n\n\n\n\n2.1.3 Getting Help with Functions\nAs you progress in R, you will learn many different functions and it can be difficult to keep track of all of the different arguments. Whenever you want to know more about what a function does or what arguments it takes, simply type ?function_name into the RStudio console and you will get some useful documentation in the Help pane located in the lower-right of your RStudio window.\n?sum\n\n\n\nCheck Your Understanding:\nLet’s take a quick pause to make sure we understand what we’ve just learned.\n\nCreate a vector of three numbers and assign it to a variable called first_vector. Now use the mean() function to find the average of first_vector.\nNow create another vector called second_vector which contains the first_vector and an NA value. Try it on your own first, then click on this footnote to see the answer.1\nUsing the na.rm = TRUE argument, calculate the mean of second_vector."
  },
  {
    "objectID": "working-with-data-in-r.html#packages",
    "href": "working-with-data-in-r.html#packages",
    "title": "2  Working with Data in R",
    "section": "2.2 Packages",
    "text": "2.2 Packages\nOne of the great benefits of R is its power and flexibility. We’ve seen how functions provide us with the ability to reuse code, but functions are common to any programming language or statistical software.\nIt may sound cliché, but what makes R special is its community. R is a free and open-source software, which means that anyone can use or contribute to it. If you develop a new statistical method, for instance, you can write the code necessary to implement it and share it with others.\nBase R, which you installed last class, comes with a number of built-in functions like mean(), sum(), range(), and var() . But, R users working out of the goodness of their hearts have developed many other functions that accomplish an array of tasks, from making aesthetically-pleasing visualizations to executing complex machine learning algorithms.\nThese functions are put together into what are called packages, which can be easily installed and loaded into R. Packages can also contain data and other compiled code.\n\n2.2.1 Installing Packages\nWe’re going to use the install.packages() function to install one such package, called tidyverse.\ninstall.packages('tidyverse')\nOnce you’ve run this command in your RStudio console, you will have downloaded the tidyverse and saved it to your library. The library is simply where your packages are stored.\nTidyverse is actually a set of packages, including dplyr and ggplot2, all of which are useful for data analysis in R. We’ll be using the tidyverse throughout this course and you will find that it’s the most commonly used set of packages for data analysis in R.\n\n\n2.2.2 Loading Libraries\nWhenever you start an R session and want to use a package, you have to be sure to load it. Loading a package makes sure that your computer knows what functions and data are inside, so that you can call them at will.\nTo load an R package, you can use the library() function, like this:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nNow, that you’ve loaded tidyverse, you can access it’s special functions like mutate() or its data sets, like starwars. Try entering starwars in your console after you’ve loaded the tidyverse. What’s inside?"
  },
  {
    "objectID": "working-with-data-in-r.html#loading-data",
    "href": "working-with-data-in-r.html#loading-data",
    "title": "2  Working with Data in R",
    "section": "2.3 Loading Data",
    "text": "2.3 Loading Data\nGreat, you know what a function is, you have the tidyverse installed, and you’ve seen that data can be contained in packages, which are easy to install and load.\n\n2.3.1 Using Data from Packages\nLet’s install and load another package, so that we can take a look at some more data.\ninstall.packages('socviz')\n\nlibrary(socviz)\n\nThe socviz package accompanies a textbook called Data Visualization written by Kieran Healy, a Professor of Sociology at Duke University, and it contains some interesting datasets including election data from the 2016 U.S. presidential election. This dataset is stored in an object titled election. Once you have socviz installed and loaded, you can get a preview of its contents by entering the name of the object:\n\nelection\n\n# A tibble: 51 × 22\n   state     st     fips total_vote vote_margin winner party pct_margin r_points\n   &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1 Alabama   AL        1    2123372      588708 Trump  Repu…     0.277     27.7 \n 2 Alaska    AK        2     318608       46933 Trump  Repu…     0.147     14.7 \n 3 Arizona   AZ        4    2604657       91234 Trump  Repu…     0.035      3.5 \n 4 Arkansas  AR        5    1130635      304378 Trump  Repu…     0.269     26.9 \n 5 Californ… CA        6   14237893     4269978 Clint… Demo…     0.300    -30.0 \n 6 Colorado  CO        8    2780247      136386 Clint… Demo…     0.0491    -4.91\n 7 Connecti… CT        9    1644920      224357 Clint… Demo…     0.136    -13.6 \n 8 Delaware  DE       10     443814       50476 Clint… Demo…     0.114    -11.4 \n 9 District… DC       11     311268      270107 Clint… Demo…     0.868    -86.8 \n10 Florida   FL       12    9502747      112911 Trump  Repu…     0.0119     1.19\n# ℹ 41 more rows\n# ℹ 13 more variables: d_points &lt;dbl&gt;, pct_clinton &lt;dbl&gt;, pct_trump &lt;dbl&gt;,\n#   pct_johnson &lt;dbl&gt;, pct_other &lt;dbl&gt;, clinton_vote &lt;dbl&gt;, trump_vote &lt;dbl&gt;,\n#   johnson_vote &lt;dbl&gt;, other_vote &lt;dbl&gt;, ev_dem &lt;dbl&gt;, ev_rep &lt;dbl&gt;,\n#   ev_oth &lt;dbl&gt;, census &lt;chr&gt;\n\n\nFor ease of use, we’re going to store a copy of this data in a new object in our environment called election_2016.\n\nelection_2016 &lt;- election\n\nNow, we can play around with it. In addition to getting a preview of the data by entering the name of our object in the console, we can also access it through the Environment pane of our RStudio window. Click on election_2016 and you will see the full dataset.\nJust like in a spreadsheet, you can scroll through the full set of columns and rows. Remember, of course, that you cannot edit values in this view tab. This is by design. If we want to make changes to the data or perform calculations, we need to do so programmatically by using code."
  },
  {
    "objectID": "working-with-data-in-r.html#data-types-and-data-structures",
    "href": "working-with-data-in-r.html#data-types-and-data-structures",
    "title": "2  Working with Data in R",
    "section": "2.4 Data Types and Data Structures",
    "text": "2.4 Data Types and Data Structures\nThis seems about as good a point as any to talk about the different types of data you will encounter in R.\n\n2.4.1 Data Types\nThere are six different basic data types in R. The most important for our purposes are:\n\ncharacter: letters such as 'a' or sets of letters such as 'apple'\nnumeric: numbers such as 1, 1.1 or 23\nlogical: the boolean values, TRUE and FALSE\n\nThe other types of data are integers (which can only hold integers and take the form 1L), complex (as in complex numbers with an imaginary component, 1+2i), and raw (data in the form of bytes). You have already used the previous three and we won’t use the latter three in this course.\nIf you wish to check the data type, or class, of an object, you can use the class() function.\n\nclass(my_vector)\n\n[1] \"numeric\"\n\n\n\n\n2.4.2 Data Structures\nThere are many different data structures in R. You’ve already become familiar with one, vectors, a set of values of the same type. Other data structures include:\n\nlist: a set of values of different types\nfactor: an ordered set of values, often used to define categories in categorical variables\ndata frame: a two-dimensional table consisting of rows and columns similar to a spreadsheet\ntibble: a special version of a data frame from the tidyverse, intended to keep your data nice and tidy\n\nNote that data structures are usually subsettable, which means that you can access elements of them. Observe:\n\nmy_list &lt;- c('a', 'b', 'c', 2)\nmy_list[2]\n\n[1] \"b\"\n\n\nIn the example above, we’ve called an element of the list, my_list, using an index number in a set of brackets. Since we entered the number 2 inside brackets next to our list name, we received the second element of the list, the character 'b'. We can also modify elements of a list in the same way.\nLet’s now say that we want to change 'b', the second element of my_list, to the word 'blueberry':\n\nmy_list[2] &lt;- 'blueberry'\nmy_list\n\n[1] \"a\"         \"blueberry\" \"c\"         \"2\"        \n\n\nEasy enough. Now try it out yourself:\n\nCreate a vector with three elements: “sociology”, “economics”, and “psychology”\nCall each of them individually.\nChange the value of the second element to the value of the first element.\nChange the value of the third element to the value of the first element.\n\nBe sure to do the last two programmatically rather than by re-typing the initial values."
  },
  {
    "objectID": "working-with-data-in-r.html#using-functions-with-data",
    "href": "working-with-data-in-r.html#using-functions-with-data",
    "title": "2  Working with Data in R",
    "section": "2.5 Using Functions with Data",
    "text": "2.5 Using Functions with Data\nBack to the elections data. We have our 2016 U.S. Presidential Election data stored in a tibble called election_2016.\nIf we want to output a single column from the data, like state, we can do so by typing in the name of the data object (in this case, election_2016) followed by the $ symbol, and the name of the column (state).\n\nelection_2016$state\n\n [1] \"Alabama\"              \"Alaska\"               \"Arizona\"             \n [4] \"Arkansas\"             \"California\"           \"Colorado\"            \n [7] \"Connecticut\"          \"Delaware\"             \"District of Columbia\"\n[10] \"Florida\"              \"Georgia\"              \"Hawaii\"              \n[13] \"Idaho\"                \"Illinois\"             \"Indiana\"             \n[16] \"Iowa\"                 \"Kansas\"               \"Kentucky\"            \n[19] \"Louisiana\"            \"Maine\"                \"Maryland\"            \n[22] \"Massachusetts\"        \"Michigan\"             \"Minnesota\"           \n[25] \"Mississippi\"          \"Missouri\"             \"Montana\"             \n[28] \"Nebraska\"             \"Nevada\"               \"New Hampshire\"       \n[31] \"New Jersey\"           \"New Mexico\"           \"New York\"            \n[34] \"North Carolina\"       \"North Dakota\"         \"Ohio\"                \n[37] \"Oklahoma\"             \"Oregon\"               \"Pennsylvania\"        \n[40] \"Rhode Island\"         \"South Carolina\"       \"South Dakota\"        \n[43] \"Tennessee\"            \"Texas\"                \"Utah\"                \n[46] \"Vermont\"              \"Virginia\"             \"Washington\"          \n[49] \"West Virginia\"        \"Wisconsin\"            \"Wyoming\"             \n\n\nThe $ is known as a subset operator and allows us to access a single column from a table. If we want to perform a calculation on a column, we can use the column as an argument in a function like so:\n\n# Sum the total number of votes cast in the 2016 Presidential election.\nsum(election_2016$total_vote, na.rm = TRUE)\n\n[1] 137125484\n\n\nHere, we summed all of the values in the total_vote column in the election_2016 tibble. The na.rm argument isn’t strictly necessary in this case (since there are no missing or unknown values), but it’s good to remember that it’s an option in case you need it."
  },
  {
    "objectID": "working-with-data-in-r.html#exercise",
    "href": "working-with-data-in-r.html#exercise",
    "title": "2  Working with Data in R",
    "section": "2.6 Exercise",
    "text": "2.6 Exercise\nFor the remainder of today’s session, I’d like you to play around with the election data. In particular:\n\nIdentify the data type for the ST, pct_johnson, and winner columns.\nCalculate the mean vote_margin across the states.\nUse the table() function to count the number of states won by each presidential candidate.\nCreate a variable which contains the total number of votes received by Hillary Clinton (contained in the column clinton_vote) and a variable containing the total number of votes received by Donald Trump (trump_vote). Take the difference of the two.\nCreate a variable containing the total number of electoral votes received by Hillary Clinton (contained in ev_dem) and another containing the total number received by Donald Trump (ev_rep). Take the difference of the two.\nTry using the plot(x=, y=) function to plot a couple of numeric columns."
  },
  {
    "objectID": "working-with-data-in-r.html#footnotes",
    "href": "working-with-data-in-r.html#footnotes",
    "title": "2  Working with Data in R",
    "section": "",
    "text": "second_vector &lt;- c(first_vector, NA)↩︎"
  },
  {
    "objectID": "summarizing-with-dplyr.html#basic-description-with-base-r",
    "href": "summarizing-with-dplyr.html#basic-description-with-base-r",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.1 Basic Description with Base R",
    "text": "3.1 Basic Description with Base R\nLet’s use an example to get us started. Last class, you toyed around with the 2016 U.S. presidential election data from the socviz package, a helpful collection of data sets and other goodies developed by Kieran Healy.2\nWe’ll use another data set from the same package in a moment, but, for now, let’s return to the election data. We’re also going to re-load our new best friend, the tidyverse package.\n\nlibrary(socviz)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nLibraries loaded. Remember, once you have the packages installed, you don’t need to do it again. So, don’t include install.packages() in your scripts going forward.3\nWe’ll load the data into an object in our environment. This time, we’ll use a slightly shorter name for the tibble to spare ourselves some future misery. A longer name means more to retype later.\n\nelec_2016 &lt;- election\n\nJust like last time, we can do basic calculations on columns using the subset operator and column name. Let’s add a few new functions to our repertoire for good measure:\n\n# table() gives a contingency table for character variables.\n# Here's the number of states (plus D.C.) won by each candidate.\ntable(elec_2016$winner)\n\n\nClinton   Trump \n     21      30 \n\n\n\n# Wrapping prop.table() around a contingency table gives relative frequencies.\n# i.e., Hillary Clinton won 41.2% (21/51) of states (plus Washington D.C.).\nprop.table(table(elec_2016$winner))\n\n\n  Clinton     Trump \n0.4117647 0.5882353 \n\n\n\n# summary() gives us a nice 5-number summary for numeric variables.\n# Here we see the min, max, median, mean, and quartiles for the pop. vote margin.\nsummary(elec_2016$vote_margin)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2736   96382  212030  383997  522207 4269978 \n\n\nBut, what if we want to do something more specific? What if, for example, we really want to know how much of the popular vote third-party Libertarian candidate Gary Johnson won across the different regions of the United States? Here we need special functions from dplyr and the pipe operator.\n\n# An illustrative example - no need to try this yet\nelec_2016 %&gt;%\n  group_by(census) %&gt;%\n  summarize(total = sum(johnson_vote))\n\n# A tibble: 4 × 2\n  census      total\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Midwest   1203062\n2 Northeast  676192\n3 South     1370056\n4 West      1239925\n\n\nWe’ll learn how to create frequency tables like this and more in a moment."
  },
  {
    "objectID": "summarizing-with-dplyr.html#the-pipe-operator",
    "href": "summarizing-with-dplyr.html#the-pipe-operator",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.2 The Pipe Operator",
    "text": "3.2 The Pipe Operator\n\nThe pipe operator is a handy tool indeed. It is a specialized operator that comes from the magrittr package, which is contained in the tidyverse.\nIt looks like this: %&gt;%. But, it can also look like this: |&gt;.\nThere isn’t much of a difference between the two, so you can use whichever you prefer as long as you are consistent.4 The pipe operator has a straightforward function: it combines a series of steps into a single command and it does this in a way which keeps your code legible. Whenever you see the pipe operator, you should read it as though it is saying, “And then [do this]” (Healy 2019).\nSo in the previous example provided, you might read the code as saying:\n\nelec_2016 %&gt;%                            # Take the election data AND THEN\n  group_by(census) %&gt;%                   # group it by census region AND THEN\n  summarize(total = sum(johnson_vote))   # sum up the vote for Johnson.\n\nNote a couple of things here:\n\nThe pipe operator always goes at the end of each line, followed by a new line\nThe pipe operator never goes at the end of the command\n\nThe first is a convention to make the code more readable and the second is a requirement. If you leave a pipe operator at the end of your statement, R will search for the missing code and then give you an unfriendly error when you try to run more code. Don’t leave a pipe operator hanging."
  },
  {
    "objectID": "summarizing-with-dplyr.html#functions-from-dplyr",
    "href": "summarizing-with-dplyr.html#functions-from-dplyr",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.3 Functions from dplyr",
    "text": "3.3 Functions from dplyr\ndplyr (pronounced dee-ply-R) is a set of tools for working with tabular data. It’s one of the packages in tidyverse (along with ggplot2, tidyr, tibble, readr, and a few others), so you won’t have to load it separately.\ndplyr has a handful of special functions:\n\ngroup_by(), which groups data together at some desired level (e.g., states by census region)\nfilter(), which gives us the rows corresponding to the criteria entered as an argument\nselect(), which selects columns from the original data\nsummarize() or summarise(), which performs calculations5\nmutate(), which creates new columns (or variables)\narrange(), which sorts the row order by column values"
  },
  {
    "objectID": "summarizing-with-dplyr.html#glimpsing-gss-data",
    "href": "summarizing-with-dplyr.html#glimpsing-gss-data",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.4 Glimpsing GSS Data",
    "text": "3.4 Glimpsing GSS Data\nLet’s load another data set from socviz so that we can start testing out these new function. This data set is called gss_sm and contains a nice, clean extract from the 2016 General Social Survey.\n\n# Loading the data into a new object\ngss &lt;- gss_sm\n\nThe General Social Survey is a nationally representative biennial survey of U.S. adults on sociological topics produced by the National Opinion Research Center (NORC) at the University of Chicago since 1972.\nTake a quick look at the data. You can use glimpse(), another dplyr function, to get a sense of what’s inside. You can also inspect it visually using view(). Typing in ?gss_sm (the original name of the data set from the package) will tell you what variables the data contains.6\n\nview(gss)\nglimpse(gss)\n\nThere’s a wealth of data in here. As you scroll through the columns and rows, you may have also noticed that the data here is at the individual-level. Each row represents an individual respondent (identified by the id variable) and each column consists of a variable (in this case, a coded response to a survey question).\nIf we click on our data in the environment pane, we can see that the first data row corresponds to respondent #1 who is 47 years old and has 3 children:"
  },
  {
    "objectID": "summarizing-with-dplyr.html#selecting-columns",
    "href": "summarizing-with-dplyr.html#selecting-columns",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.5 Selecting Columns",
    "text": "3.5 Selecting Columns\nThere are 32 variables in this data set. Maybe we want to narrow in and look at just a few of them, like: id, sex, and religion. We can use the select() function to do this.\n\ngss %&gt;%                             # Take the GSS data AND THEN\n  select(id, sex, religion)         # take just the ID, sex, and religion columns.\n\n# A tibble: 2,867 × 3\n      id sex    religion  \n   &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;     \n 1     1 Male   None      \n 2     2 Male   None      \n 3     3 Male   Catholic  \n 4     4 Female Catholic  \n 5     5 Female None      \n 6     6 Female None      \n 7     7 Male   None      \n 8     8 Female Catholic  \n 9     9 Male   Protestant\n10    10 Male   None      \n# ℹ 2,857 more rows\n\n\nIn the code above, we told R that we wanted to take the GSS data and then (using the pipe operator) only the id, sex, and religion variables. The select function outputs a new tibble containing only those three variables entered as arguments. The number of rows or observations, 2,867, is the same as in the original data.\nWe can now save a copy of our new three-variable tibble by assigning it to a new object. Let’s call this new object gender_relig.\n\ngender_relig &lt;- gss %&gt;%\n  select(id, sex, religion)\n\nNow we have a new object containing our new tibble. If after inspecting this new tibble you decide that you don’t need or want it anymore, you can always get rid of it using the rm() function.7\n\nview(gender_relig)\nrm(gender_relig)"
  },
  {
    "objectID": "summarizing-with-dplyr.html#grouping-and-summarizing",
    "href": "summarizing-with-dplyr.html#grouping-and-summarizing",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.6 Grouping and Summarizing",
    "text": "3.6 Grouping and Summarizing\nLet’s say we want a table which shows the number of respondents by religious affiliation. There are other ways of doing this, but we’re going to use dplyr and the pipe operator.\nTo do this, we first have to tell R how we would like to group the data. Grouping doesn’t visibly change the data, but it prepares R to interpret our next commands according to the groups we specify. We’re going to group by the religion variable which contains the respondent’s religious affiliation.\n\ngss %&gt;%\n  group_by(religion)\n\n# A tibble: 2,867 × 32\n# Groups:   religion [6]\n    year    id ballot       age childs sibs   degree race  sex   region income16\n   &lt;dbl&gt; &lt;dbl&gt; &lt;labelled&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;labe&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;   \n 1  2016     1 1             47      3 2      Bache… White Male  New E… $170000…\n 2  2016     2 2             61      0 3      High … White Male  New E… $50000 …\n 3  2016     3 3             72      2 3      Bache… White Male  New E… $75000 …\n 4  2016     4 1             43      4 3      High … White Fema… New E… $170000…\n 5  2016     5 3             55      2 2      Gradu… White Fema… New E… $170000…\n 6  2016     6 2             53      2 2      Junio… White Fema… New E… $60000 …\n 7  2016     7 1             50      2 2      High … White Male  New E… $170000…\n 8  2016     8 3             23      3 6      High … Other Fema… Middl… $30000 …\n 9  2016     9 1             45      3 5      High … Black Male  Middl… $60000 …\n10  2016    10 3             71      4 1      Junio… White Male  Middl… $60000 …\n# ℹ 2,857 more rows\n# ℹ 21 more variables: relig &lt;fct&gt;, marital &lt;fct&gt;, padeg &lt;fct&gt;, madeg &lt;fct&gt;,\n#   partyid &lt;fct&gt;, polviews &lt;fct&gt;, happy &lt;fct&gt;, partners &lt;fct&gt;, grass &lt;fct&gt;,\n#   zodiac &lt;fct&gt;, pres12 &lt;labelled&gt;, wtssall &lt;dbl&gt;, income_rc &lt;fct&gt;,\n#   agegrp &lt;fct&gt;, ageq &lt;fct&gt;, siblings &lt;fct&gt;, kids &lt;fct&gt;, religion &lt;fct&gt;,\n#   bigregion &lt;fct&gt;, partners_rc &lt;fct&gt;, obama &lt;dbl&gt;\n\n\nAs you can see, our data doesn’t appear to have changed in the output above. We still have 32 variables and 2,867 observations. But, there is now a helpful note at the top of our output that says, Groups: religion[6]. Our observations have been successfully grouped according to the six religious affiliations in our data.\nNext, we have to add another line to our pipe function which specifies how we want to summarize() the groups. Remember, for each of these additions to our pipe function we’re adding a pipe operator the end of each line, except for the last line. We want it to count up our rows here, so we’ll use the n() function. The n() function counts the number of rows in a data frame.8\n\ngss %&gt;%\n  group_by(religion) %&gt;%      # Group by religion\n  summarize(total = n())      # Create a total by counting the rows\n\n# A tibble: 6 × 2\n  religion   total\n  &lt;fct&gt;      &lt;int&gt;\n1 Protestant  1371\n2 Catholic     649\n3 Jewish        51\n4 None         619\n5 Other        159\n6 &lt;NA&gt;          18\n\n\nAs you can see, we provided summarize() with a new column name, total, and a measurement, n(). The pipe operator between the two lines ensured that we grouped our data first and then summarized. Now, we have the total number of respondents for each group (religious affiliation).\nIf we want, we can save a copy of our new tibble in another object, as in the command below. The original data object in our environment (i.e., gss) will always remain untouched unless we intentionally re-assign it (i.e., gss &lt;- gss %&gt;% ...).\n\nrelig &lt;- gss %&gt;%\n  group_by(religion) %&gt;%\n  summarize(total = n())\n\nAnother quick example, let’s say we want to see the count of our 2016 GSS respondents by sex:\n\ngss %&gt;%\n  group_by(sex) %&gt;%\n  summarize(total = n())\n\n# A tibble: 2 × 2\n  sex    total\n  &lt;fct&gt;  &lt;int&gt;\n1 Male    1276\n2 Female  1591\n\n\nIn this code snippet, we took the GSS data and then grouped it by sex and then summarized it by creating a total which holds a count of the number of rows. Since the number of rows corresponds to the number of respondents who took the 2016 GSS, we can see that 1,276 respondents were male and 1,591 were female.\n\n3.6.1 Grouping by Two Variables\nWe can also create the equivalent of what is called a two-way contingency table by grouping with two variables at the same time. To do this, we add the second variable as another argument in the group_by() function. We can find religious affiliation by sex like this:\n\ngss %&gt;%\n  group_by(religion, sex) %&gt;%\n  summarize(total = n())\n\n`summarise()` has grouped output by 'religion'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 12 × 3\n# Groups:   religion [6]\n   religion   sex    total\n   &lt;fct&gt;      &lt;fct&gt;  &lt;int&gt;\n 1 Protestant Male     559\n 2 Protestant Female   812\n 3 Catholic   Male     287\n 4 Catholic   Female   362\n 5 Jewish     Male      22\n 6 Jewish     Female    29\n 7 None       Male     339\n 8 None       Female   280\n 9 Other      Male      58\n10 Other      Female   101\n11 &lt;NA&gt;       Male      11\n12 &lt;NA&gt;       Female     7\n\n\nIn the output above, we can now identify the number of Protestants who are male, 559, and the number who are female, 812.\n\n\n3.6.2 Ordering group_by() Arguments\nIt is worth noting that the ordering of arguments in the group_by() function sometimes matters (i.e., group_by(religion, sex) as opposed to group_by(sex, religion).\nBecause religion came first in our argument order, our results show us the number of Protestants who are male and the number of Protestants who are female. But, we could have very easily shown the number of males who are Protestant and the number of females who are Protestant.\nFor a count, these are the same thing. The number of Protestants who are male is the same as the number of males who are Protestant. But when we start calculating relative frequencies and percentages using group_by(), the order will matter.9 You’ll get a sense for this in a moment."
  },
  {
    "objectID": "summarizing-with-dplyr.html#calculating-with-mutate",
    "href": "summarizing-with-dplyr.html#calculating-with-mutate",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.7 Calculating with mutate()",
    "text": "3.7 Calculating with mutate()\nIs there an equal proportion of male and female Protestants in the GSS? Let’s add a relative frequency column to find out.\n\ngss %&gt;%\n  group_by(religion, sex) %&gt;%\n  summarize(total = n()) %&gt;%\n  mutate(freq = total / sum(total),\n         pct = round((freq*100), 1))\n\n`summarise()` has grouped output by 'religion'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 12 × 5\n# Groups:   religion [6]\n   religion   sex    total  freq   pct\n   &lt;fct&gt;      &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Protestant Male     559 0.408  40.8\n 2 Protestant Female   812 0.592  59.2\n 3 Catholic   Male     287 0.442  44.2\n 4 Catholic   Female   362 0.558  55.8\n 5 Jewish     Male      22 0.431  43.1\n 6 Jewish     Female    29 0.569  56.9\n 7 None       Male     339 0.548  54.8\n 8 None       Female   280 0.452  45.2\n 9 Other      Male      58 0.365  36.5\n10 Other      Female   101 0.635  63.5\n11 &lt;NA&gt;       Male      11 0.611  61.1\n12 &lt;NA&gt;       Female     7 0.389  38.9\n\n\nNotice, we used the same code as before, but we’ve now added another step, a mutate() function to create two new columns, freq (relative frequency) and pct (percentage).\nWe previously calculated the total or the number of observations for each sub-group (e.g., Protestants who are males, Protestants who are females, etc.). The mutate() function takes the total we calculated in the previous step and uses it to calculate first the relative frequency and then the percentage for each sub-group.\nTo calculate the relative frequency, we used freq = total / sum(total) or in plain English “create a new value called freq and then calculate this value by taking the number of observations for each sub-group (total) and then dividing it by the sum of the totals for all sub-groups (sum(total)).”\nFor the religious group Protestant, we have two sub-groups, male and female, and so the frequency for males Protestants is calculated as 559 / (559 + 812), which equals 0.408 , or exactly what you see in the first row in the frequency column in our new tibble. Similarly, the frequency for female Protestants would be 812 / (559 + 812) or 0.592 or what you see in the frequency column in the second row of our new tibble.\nWhat about the percentage or pct? In the second argument of our mutate() function, we told R to take the freq we calculated in the previous step, multiply it by 100 (to make it a percentage), and then round it to the first decimal place using the round() function. 0.408, the relative frequency of male Protestants, therefore becomes 40.8%.\nAs you can see, calculating relative frequencies and percentages using dplyr and the pipe function can be a bit of a beast. The good news is that the general form is always the same and so you’ll be able to re-use the code often."
  },
  {
    "objectID": "summarizing-with-dplyr.html#how-r-reads-functions",
    "href": "summarizing-with-dplyr.html#how-r-reads-functions",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.8 How R Reads Functions",
    "text": "3.8 How R Reads Functions\nIn the previous examples, you may have noticed a bunch of nested functions, which is when a function is used as an argument inside another functions, e.g., summarize(total = n()). It’s worth pausing for a moment to think about how R reads code, since you will be using these types of constructions quite often.\nFunctions are always read inside out, so a nested function will always evaluate the inner-most function first. Pipe operations, on the other hand, are always read from left-to-right or top-to-bottom (if you’re breaking up your code using new lines, as you should be). The two commands below evaluate in the same way, but R reads them in a slightly different ordering.\n\n# Inside-out evaluation\nsum(c(1,2,3))               # A vector, {1,2,3} is created first AND THEN summed\n\n[1] 6\n\n# Left-to-right/top-to-bottom (sequential) evaluation\nc(1,2,3) %&gt;%                # A vector is created AND THEN\n  sum()                     # it is summed\n\n[1] 6\n\n\nIn both cases, a vector is being created first and then summed."
  },
  {
    "objectID": "summarizing-with-dplyr.html#filtering",
    "href": "summarizing-with-dplyr.html#filtering",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.9 Filtering",
    "text": "3.9 Filtering\nBack to the data. What if we only wanted to see the Protestant results for our previous examples? We can use a filter() function.\n\ngss %&gt;%\n  group_by(religion, sex) %&gt;%\n  summarize(total = n()) %&gt;%\n  mutate(freq = total / sum(total),\n         pct = round((freq*100), 1)) %&gt;%\n  filter(religion == \"Protestant\")\n\n`summarise()` has grouped output by 'religion'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 5\n# Groups:   religion [1]\n  religion   sex    total  freq   pct\n  &lt;fct&gt;      &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Protestant Male     559 0.408  40.8\n2 Protestant Female   812 0.592  59.2\n\n\nIn a filter function, you use logical and comparison operators (see the slides from Session 3 if you’d like a refresher) to define the criteria for your new tibble. In this case, we want only the observations for which the religion variable is equal to “Protestant”.\nR is case-sensitive and so if the values in your data are “protestant”, for example, you won’t see those results in the tibble output here.\nUsually, you will want to use the filter() function at the beginning of your query. Here’s another example. This time, we’re only interested in religious affiliation among holders of graduate degrees.\n\ngss %&gt;%\n  filter(degree == 'Graduate') %&gt;%\n  group_by(religion) %&gt;%\n  summarize(total = n()) %&gt;%\n  mutate(freq = total / sum(total),\n         pct = round((freq*100), 1))\n\n# A tibble: 6 × 4\n  religion   total    freq   pct\n  &lt;fct&gt;      &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Protestant   126 0.396    39.6\n2 Catholic      63 0.198    19.8\n3 Jewish        15 0.0472    4.7\n4 None          82 0.258    25.8\n5 Other         31 0.0975    9.7\n6 &lt;NA&gt;           1 0.00314   0.3\n\n\nNow, we can see that 39.6% of graduate-degree holding respondents were Protestant and 25.8% had no religious affiliation. Later on, we’ll learn how to turn this sort of thing into a nice graph.\n\n# What happens if I use a lower-case 'g' in 'Graduate' instead?\ngss %&gt;%\n  filter(degree == 'graduate') %&gt;%\n  group_by(religion) %&gt;%\n  summarize(total = n()) %&gt;%\n  mutate(freq = total / sum(total),\n         pct = round((freq*100), 1))\n\n# A tibble: 0 × 4\n# ℹ 4 variables: religion &lt;fct&gt;, total &lt;int&gt;, freq &lt;dbl&gt;, pct &lt;dbl&gt;"
  },
  {
    "objectID": "summarizing-with-dplyr.html#conditional-filtering",
    "href": "summarizing-with-dplyr.html#conditional-filtering",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.10 Conditional Filtering",
    "text": "3.10 Conditional Filtering\nWhat if we want to filter our respondents for multiple degree types? We may want to see in our table of religious affiliation, for example, only people who have a bachelor’s degree or a graduate degree.\nFor these types of queries, we can use other logical operators in our filter() criteria. Here, specifically, we’ll use | which stands for ‘or’.\n\ngss %&gt;%\n  filter(degree == 'Graduate' | degree == 'Bachelor') %&gt;%\n  group_by(religion) %&gt;%\n  summarize(total = n()) %&gt;%\n  mutate(freq = total / sum(total),\n         pct = round((freq*100), 1))\n\n# A tibble: 6 × 4\n  religion   total    freq   pct\n  &lt;fct&gt;      &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Protestant   367 0.430    43  \n2 Catholic     193 0.226    22.6\n3 Jewish        27 0.0316    3.2\n4 None         204 0.239    23.9\n5 Other         59 0.0691    6.9\n6 &lt;NA&gt;           4 0.00468   0.5\n\n\nNow our results include only college graduates and graduate degree holders. If we want to see them broken out separately after we have filtered, all we need to do is change group_by(religion) to group_by(religion, degree).\nWhat if we want to filter our observations for all individuals with less than a bachelor’s degree? We can create a vector with our specific criteria and then use it in our filter argument. Look at this:\n\nfilter_criteria &lt;- c('Lt High School', 'High School', 'Junior College')\n\ngss %&gt;%\n  filter(degree %in% filter_criteria) %&gt;%\n  group_by(religion, degree) %&gt;%\n  summarize(total = n()) %&gt;%\n  mutate(freq = total / sum(total),\n         pct = round((freq*100), 1))\n\n`summarise()` has grouped output by 'religion'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 17 × 5\n# Groups:   religion [6]\n   religion   degree         total   freq   pct\n   &lt;fct&gt;      &lt;fct&gt;          &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Protestant Lt High School   155 0.155   15.5\n 2 Protestant High School      742 0.740   74  \n 3 Protestant Junior College   106 0.106   10.6\n 4 Catholic   Lt High School   100 0.220   22  \n 5 Catholic   High School      322 0.708   70.8\n 6 Catholic   Junior College    33 0.0725   7.3\n 7 Jewish     Lt High School     1 0.0417   4.2\n 8 Jewish     High School       17 0.708   70.8\n 9 Jewish     Junior College     6 0.25    25  \n10 None       Lt High School    62 0.150   15  \n11 None       High School      298 0.722   72.2\n12 None       Junior College    53 0.128   12.8\n13 Other      Lt High School    10 0.1     10  \n14 Other      High School       73 0.73    73  \n15 Other      Junior College    17 0.17    17  \n16 &lt;NA&gt;       High School        9 0.9     90  \n17 &lt;NA&gt;       Junior College     1 0.1     10  \n\n\nWe’ve first created a vector, called filter_criteria, with all of the degree-levels we want to include in our data (we’ve left out ‘Graduate’ and ‘Bachelor’). Then, we’ve set the filter criteria to say, “Take all respondents who have a degree listed in our vector, filter_criteria.” In code, we write this as: filter(degree %in% filter_criteria).\n\n3.10.1 The %in% Operator\n%in% is a special logical operator that checks to see whether the values you are specifying are contained in an object. If the value is contained in the object, your computer will return TRUE and if not, it will return FALSE. This is especially useful for filter() since filter() selects rows based on whether they meet a criteria (TRUE) or not (FALSE).\nHere’s a simple example of how this operator works in general:\n\n1 %in% c(1,2,3,4,5)\n\n[1] TRUE\n\n\n\n6 %in% c(1,2,3,4,5)\n\n[1] FALSE"
  },
  {
    "objectID": "summarizing-with-dplyr.html#fancy-tables-with-kable",
    "href": "summarizing-with-dplyr.html#fancy-tables-with-kable",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.11 Fancy Tables with kable()",
    "text": "3.11 Fancy Tables with kable()\nIf we want to make a summary table look a little bit nicer, we can add the knitr::kable() function to the end of our query to produce something more polished.\n\ngss %&gt;%\n  filter(degree == 'Graduate') %&gt;%\n  group_by(religion) %&gt;%\n  summarize(total = n()) %&gt;%\n  mutate(freq = total / sum(total),\n         pct = round((freq*100), 1)) %&gt;%\n  knitr::kable()\n\n\n\n\nreligion\ntotal\nfreq\npct\n\n\n\n\nProtestant\n126\n0.3962264\n39.6\n\n\nCatholic\n63\n0.1981132\n19.8\n\n\nJewish\n15\n0.0471698\n4.7\n\n\nNone\n82\n0.2578616\n25.8\n\n\nOther\n31\n0.0974843\n9.7\n\n\nNA\n1\n0.0031447\n0.3\n\n\n\n\n\nThe :: operator here tells R to pull the kable() function from the knitr package (which is located in the tidyverse). This is useful when there are multiple functions with the same name in different packages.\nYou can also add additional code to your kable() function to customize the look of your table (see here for examples)."
  },
  {
    "objectID": "summarizing-with-dplyr.html#another-example",
    "href": "summarizing-with-dplyr.html#another-example",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.12 Another Example",
    "text": "3.12 Another Example\nWhat if we want to do something ultra-specific like find all survey respondents who are Protestant or Catholic, voted for Obama in the 2012 U.S. Presidential election, and have children? And, we’d like to know their breakdown by relative frequency across regions of the U.S.\nHere’s a brief example:\n\ngss %&gt;%\n  filter(religion == \"Protestant\" | religion == \"Catholic\") %&gt;%\n  filter(obama == 1) %&gt;%\n  filter(childs &gt; 0) %&gt;%\n  group_by(region) %&gt;%\n  summarize(total = n()) %&gt;%\n  mutate(freq = round(total / sum(total),4),\n         pct = round((freq*100), 1))\n\n# A tibble: 9 × 4\n  region          total   freq   pct\n  &lt;fct&gt;           &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 New England        33 0.0602   6  \n2 Middle Atlantic    57 0.104   10.4\n3 E. Nor. Central   119 0.217   21.7\n4 W. Nor. Central    36 0.0657   6.6\n5 South Atlantic    121 0.221   22.1\n6 E. Sou. Central    35 0.0639   6.4\n7 W. Sou. Central    57 0.104   10.4\n8 Mountain           35 0.0639   6.4\n9 Pacific            55 0.100   10  \n\n\nNow we have the skills to find the percentage of Protestants and/or Catholics with children who voted for Obama in 2012 and reside in the South Atlantic census region (29.2%)."
  },
  {
    "objectID": "summarizing-with-dplyr.html#practice-exploring-data",
    "href": "summarizing-with-dplyr.html#practice-exploring-data",
    "title": "3  Summarizing Data with dplyr",
    "section": "3.13 Practice Exploring Data",
    "text": "3.13 Practice Exploring Data\nYou can see here that the dplyr functions provide an enormous amount of flexibility and power. R, like other programming languages, is also very sensitive to mistakes in syntax or spelling: a missing comma in a set of function arguments, a hanging pipe operator, a misspelled filter criteria, or an erroneous object name can all cause output errors. Check your code carefully, take a deep breath, and try again. You’ll get the hang of it in no time.\nUse the remainder of class time today to explore the gss_sm data. Try summarizing different variables according to different groupings. Try using other measures like mean() or sd() to summarize numeric variables (like the number of children).\nIf you are feeling overwhelmed at the moment - don’t despair, we’re going to continue practicing these skills throughout the rest of the course.\n\n\n\n\nHealy, Kieran. 2019. Data Visualization: A Practical Introduction. Princeton: Princeton University Press. socviz.co."
  },
  {
    "objectID": "summarizing-with-dplyr.html#footnotes",
    "href": "summarizing-with-dplyr.html#footnotes",
    "title": "3  Summarizing Data with dplyr",
    "section": "",
    "text": "Sadly, almost all data you encounter out in the wild will be very unseemly for one reason or another. But, maybe after taking this course and ascending the ranks of government/business/academia, you too will become an evangelical for orderly data and help to make the world a tidier place.↩︎\nThe socviz package serves as an accompaniment to Healy’s textbook, Data Visualization, which is highly recommended.↩︎\nAnytime you install packages, do it directly in the console. If someone needs to run your code, they should see the library() calls in the beginning of your code after the header and will know whether they need to install additional packages or not. RStudio also has a helpful auto-prompt feature that will let you know if you are missing anything.\nInstead of the library() function, you can also use require(), which has the benefit loading packages if you already have them and installing them if you don’t.↩︎\nFor more on the differences between the two pipe operators, see here: https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe↩︎\nsummarize() and summarise() are the same function, just two different spellings, the choice of which depends on who you’ve learned English from.↩︎\nYou won’t always be able to get documentation on a data set by using the help function, unfortunately. But, in this case, it works because socviz comes with documentation that was downloaded when you installed the package. Note that you must refer to the data in your help query by it’s original name (?gss_sm not ?gss).↩︎\nUsing the rm() function can help keep your environment a bit more orderly, but it isn’t always necessary since your environment will be cleared out each time you close RStudio anyways.↩︎\nThere are other options for counting the number of rows, like the count() or tally() functions, but I won’t use them here.↩︎\nThe percentage of Protestants who are male is not the same as the percentage of males who are Protestant.↩︎"
  },
  {
    "objectID": "visualizing-with-ggplot.html#descriptive-statistics",
    "href": "visualizing-with-ggplot.html#descriptive-statistics",
    "title": "4  Visualizing with ggplot2",
    "section": "4.1 Descriptive Statistics",
    "text": "4.1 Descriptive Statistics\nIn the previous chapter, we learned how to use dplyr functions to summarize data. We started with individual-level observations (i.e., GSS respondents) and used group_by() , summarize(), and mutate() to distill our granular data into summary statistics, such as the proportion of GSS respondents by religious affiliation or the mean number of children by respondent’s degree level. We can’t say much yet about whether more Americans are Protestant or Catholic or whether U.S. college graduates tend to have more or less children than high school graduates — these questions require inference — but, we’re now able to produce some of the statistics we’ll need to examine these types of questions later on.\nThe point of producing descriptive statistics, like proportions or means, is that they allow us to identify characteristics of a set of observations (usually, a sample). For quantitative variables, if you recall from your statistics class, we can describe data with different types of measures. We have, for instance: measures of central tendency, which give us an indication of where the center of our distribution is (or what the typical observation may be); measures of spread, which tell us how far apart observations are from the center of the distribution; and what we might call other distributional measures, which can tell us how many values are in our sample or what the largest and smallest values may be. Categorical variables are simpler and we can generally describe them with a frequency (count) or relative frequency (the count expressed as a proportion or percentage) alone.\n\n4.1.1 Measures for a Single Quantitative Variable\nThe tables below provide a brief overview of some of the measures we’ve already used or might use to describe a quantitative variable.\n\nCentral Tendency\n\n\n\n\n\n\n\n\nMeasure\nDescription\nR Function\n\n\nMean\nThe sum of the values divided by the count. It is sensitive to outliers.\nmean()\n\n\nMedian\nThe middle value, where half of the values are above and half are below. It is resistant to outliers.\nmedian()\n\n\n\n\n\nSpread\n\n\n\n\n\n\n\n\nMeasure\nDescription\nR Function\n\n\nVariance\nThe sum of squared deviations from the mean divided by the count minus one.4 It gives us a sense of how far values typically are from the mean.\nvar()\n\n\nStandard Deviation\nThe square root of the variance.5 The more commonly reported measure of spread which, again, tells us how far values typically are from the mean.\nsd()\n\n\nInterquartile Range (IQR)\nThe distance between the 75th percentile value and the 25th percentile value. It gives us an indication of the spread for the middle-most values.\nIQR()\n\n\n\n\n\nOther Distributional Measures\n\n\n\nMeasure\nDescription\nR Function\n\n\nMinimum\nThe smallest value.\nmin()\n\n\nMaximum\nThe largest value.\nmax()\n\n\nCount\nThe number of values.\nn()\n\n\n\n\n\nExample\nBelow is a table of descriptive statistics for the popular vote share received by candidates in the 2016 U.S. Presidential election by state (including the District of Columbia). Note, the unit of observation is a U.S. state and so we can read this as saying that Trump received 4.09% of the vote share in his lowest performing state and 68.17% in his highest, with a mean of 48.26% and standard deviation of 11.92% across states.\n\n\n\n\n\ncandidate\nmedian\nmean\nvar\nsd\niqr\nmin\nmax\n\n\n\n\nTrump\n48.17\n48.26\n142.03\n11.92\n16.20\n4.09\n68.17\n\n\nClinton\n46.17\n44.61\n148.49\n12.19\n15.73\n21.88\n90.86\n\n\nJohnson\n3.44\n3.72\n2.05\n1.43\n1.79\n1.19\n9.34\n\n\nOther\n2.74\n3.41\n12.30\n3.51\n1.53\n0.00\n24.32\n\n\n\n\n\nAs a general rule, we don’t use variance in our descriptions and we report mean and standard deviation together. These latter two are especially important for certain inferential methods.\n\n\n\n4.1.2 Measure for Two Quantitative Variable\nTo these univariate characteristics, we can add a measure for describing the relationship between two quantitative variables: the correlation coefficient.\n\n\n\n\n\n\n\n\nMeasure\nDescription\nR Function\n\n\nCorrelation (\\(r\\))\nA measure of the strength and direction of the linear association between two quantitative variables.\ncor()\n\n\n\nIn statistics, we generally make a distinction between an association, a relationship between two variables, and a correlation, or the linear association between two quantitative variables. Associations can refer to some relationship between variables of any type, but a correlation is a measure we calculate for two quantitative variables using a specific formula (or the cor() function in R). The distinction between association and correlation often gets lost in everyday language, but we’ll try to maintain some precision here.\nCorrelations range between -1 and +1, with both extremes representing a perfect linear association of data points with some slope. The figure below shows a range of correlations for different sets of observations.\n\n\n\n\n\nTo describe a relationship between quantitative variables, it is useful to talk about:\n\nStrength, whether there is a strong (closer to -1 or +1) or weak correlation (closer to 0)\nDirection, whether the relationship is positive or negative\nForm, whether the association is linear or non-linear\nOutliers, whether there are observations that break the general pattern\n\nThe correlation coefficient is sensitive to outliers, which means that a stray observation can greatly influence the measure, and the general form of the relationship. You can see the effect of both in Francis Anscombe’s classic example. The figure below shows four different sets of observations, each with the same correlation (\\(r \\approx 0.82\\)) and other summary statistics."
  },
  {
    "objectID": "visualizing-with-ggplot.html#why-visualize",
    "href": "visualizing-with-ggplot.html#why-visualize",
    "title": "4  Visualizing with ggplot2",
    "section": "4.2 Why Visualize?",
    "text": "4.2 Why Visualize?\nThis brings us to the central point of this chapter: data visualization isn’t just fun, it is necessary. Correlations and other summary measures can be terribly misleading if used blindly. Checking a visual presentation of our data provides us with the opportunity to ensure that the underlying data matches our expectations. In the case of Anscombe’s quartet, only one of the plots corresponds to what we might expect for a correlation of 0.82.6\nThere are other clear benefits to data visualization beyond the purely analytic. They can convey complex data in simple terms, for instance, and they can form lasting impressions.\n\n\n\nCharles Minard’s famous, “Carte figurative des pertes successives en hommes de l’Armée Française dans la campagne de Russie 1812–1813” (Source: Wikimedia).\n\n\nThese communicative benefits can be difficult to overstate. But it is important to remember that as much as we may want to convince others with aesthetically pleasing figures, it is the underlying veracity of our visualizations which matters most. To put it bluntly, if the visualization is eye catching, but uses poor quality data, it is not a good visualization. Similarly, if the visualization presents good data in a misleading way or fails to convey any meaning at all, it is not a good visualization. We need good data to make good visualizations and we must act as good analysts to ensure that accurate meanings are being conveyed.\n\n\n\nA bar chart produced by the American sociologist W.E.B. Du Bois (1868-1963) for the Paris Exposition Universelle in 1900 to show the economic progress of African Americans after emancipation (Source: U.S. Library of Congress)."
  },
  {
    "objectID": "visualizing-with-ggplot.html#some-principles",
    "href": "visualizing-with-ggplot.html#some-principles",
    "title": "4  Visualizing with ggplot2",
    "section": "4.3 Some Principles",
    "text": "4.3 Some Principles\nWhat makes for a good visualization then? The unsatisfying answer is that it depends. But, here are at some guiding principles that may be helpful:\nAvoid features which distract from the data. Better charts, as Healy (2019) argues, usually maximize the data-to-ink ratio. This means that we don’t want to add extras when they provide no benefit to interpretation and we should ensure that the features of the visualization all speak to the data in some way. We should avoid, for example, making 3D charts when an extra dimension serves no purpose.\nAvoid perceptual traps. You have no doubt seen graphs with truncated Y-labels, which can overemphasize volatility in trends. Contrary to what you may have heard, these types of graphs can sometimes be appropriate - especially, when a small marginal change in an otherwise stable trend is of great consequence. But this sort of example belies a bigger issue, which is the challenge of matching the perception of the reader with the actual patterns in the data. You must take care not only when deciding on the appropriate scale for an axis, but also on the type of graph, the ordering and size of various elements, the choice of color gradient, and the relative width and height (aspect ratio) of the final product. Pie charts, as an example of a type of graph, happen to be particularly unintuitive because of the difficulty we human beings have in perceiving the relative size of different segments of a circle. In a bar chart, by contrast, we only need to compare the length of different bars to understand relative size, a much simpler cognitive undertaking.\nUse the right measure. When it comes to analyzing data, you will no doubt have many options in terms of the measures you can use to convey your findings. But it is equally important that you choose the measure which is most appropriate for the comparisons you are making. This is not a problem specific to data visualization, per se, but it is one which crops up all too often. If you want, for example, to compare crime rates across geographic units, you will want to adjust your data to a per capita basis.7 If you wish to compare typical worker salaries across countries, you will want to compare medians rather than means.\nIt may be apparent, in the foregoing discussion, that the most interesting visualizations generally involve two or more variables and bring the reader’s attention to the relationships between them. The principles discussed here are, of course, not intended to be exhaustive and you’ll sometimes find that the choices we make in visualizations come down to taste. At the very least, however, we should all endeavor to use visualizations to convey our information clearly and truthfully.\n\n\n\nFlorence Nightingale’s (1858), “Diagram of the causes of mortality in the army in the East.” A more effective pie chart where the perceptual relative size issue is negated by the amount of information conveyed and the potentially seasonal nature of the data."
  },
  {
    "objectID": "visualizing-with-ggplot.html#some-practicalities",
    "href": "visualizing-with-ggplot.html#some-practicalities",
    "title": "4  Visualizing with ggplot2",
    "section": "4.4 Some Practicalities",
    "text": "4.4 Some Practicalities\nThe everyday graphs we make when conducting data analysis will usually be more functional than pretty, but that doesn’t have to stop us from combining the two today. In the example below, we’ll focus mainly on the mechanics of constructing a visualization using ggplot2 rather than on how to use them analytically.\nTo get started, we’ll load a new data set called gapminder, which contains data on countries. Conveniently, the gapminder data is located in the gapminder package. As usual, we want to be sure that we’ve installed the package before loading it for the first time.\n\nlibrary(gapminder)\ndata(gapminder)\n\nThe data() function used above is an alternative to gapminder &lt;- gapminder. It loads the gapminder data from the package into a gapminder object in our environment. You can use either, but it’s good to keep learning new functions at this stage so that you can understand what they do when you see them elsewhere.\nAs will become second nature to you to you soon, we can inspect this data using glimpse(), view(), or by clicking on the object in the environment pane.\n\nglimpse(gapminder)\n\nRows: 1,704\nColumns: 6\n$ country   &lt;fct&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", …\n$ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, …\n$ year      &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, …\n$ lifeExp   &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8…\n$ pop       &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12…\n$ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, …\n\n\nOur new tibble has 1,704 rows and 6 variables (?gapminder provides some more information on the variables). There is something a little bit different about this data compared to the GSS data. Whereas in the GSS data each row corresponds to a separate observation (i.e., a respondent), in the Gapminder data, each row corresponds to a year for a particular country. We have, for instance, a row with data for Afghanistan in 1952 and another row for Afghanistan in 1957 in the next. The unit of observation here is called a “country-year.” Consider for a moment how this might affect the answers you get when using mean() or median().\nIn the social sciences, we call this format, long data. The differences in the way tabular data is stored has important implications for the way we analyze it. We’ll discuss this more in depth in the next chapter. Luckily for us, the gapminder data is already in an ideal format for ggplot2.\n\nBrief Exercise\nAs a brief exercise and to refresh your memory, let’s use dplyr to find the minimum and maximum years in the gapminder data. Try it on your own first and then check your answer below.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\ngapminder %&gt;%\n  summarize(min_year = min(year),\n            max_year = max(year))\n\n# A tibble: 1 × 2\n  min_year max_year\n     &lt;int&gt;    &lt;int&gt;\n1     1952     2007\n\n\n\n\n\nNow see whether you can find the minimum and maximum year for each country along with the number of times each country appears in the data.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\ngapminder %&gt;%\n  group_by(country) %&gt;%\n    summarize(min_year = min(year),\n              max_year = max(year),\n              n = n())\n\n# A tibble: 142 × 4\n   country     min_year max_year     n\n   &lt;fct&gt;          &lt;int&gt;    &lt;int&gt; &lt;int&gt;\n 1 Afghanistan     1952     2007    12\n 2 Albania         1952     2007    12\n 3 Algeria         1952     2007    12\n 4 Angola          1952     2007    12\n 5 Argentina       1952     2007    12\n 6 Australia       1952     2007    12\n 7 Austria         1952     2007    12\n 8 Bahrain         1952     2007    12\n 9 Bangladesh      1952     2007    12\n10 Belgium         1952     2007    12\n# ℹ 132 more rows"
  },
  {
    "objectID": "visualizing-with-ggplot.html#how-ggplot2-works",
    "href": "visualizing-with-ggplot.html#how-ggplot2-works",
    "title": "4  Visualizing with ggplot2",
    "section": "4.5 How ggplot2 Works",
    "text": "4.5 How ggplot2 Works\nBack to visualizations: much like a cake, ggplot2 involves adding layers. We start with a bare plot which has only our axes and their labels and then we work our way up to the final product, layer by layer.\n\n4.5.1 Making the Base Plot\nJust as with dplyr, we can use the pipe operator to work with ggplot2. We first take the Gapminder data and then add a new function, ggplot().\n\ngapminder %&gt;%\n  ggplot()\n\n\n\n\nWithout any arguments supplied, the ggplot() function produces a blank plot (shown above), a canvas we’ll use to paint our visualization. If you are following along in an R Script, you should be able to see this plot in the lower right pane of your R Studio window (under the ‘Plots’ tab) after running it. We’d rather see a completed canvas than a blank canvas, however, so we’re going to supply an argument called mapping. The mapping argument tells ggplot how we are going to map the data to the plot.\ngapminder %&gt;%\n  ggplot(mapping = )\nThis mapping argument, in turn, requires us to specify an ‘aesthetic’ which will always be contained in an aes() function. So now we have:\ngapminder %&gt;%\n  ggplot(mapping = aes())\nIf we were to run this, we would still get a blank plot. The ggplot() function knows we’re using the gapminder data (since we used the pipe operator), but it doesn’t yet know what we would like to see on our x- or y-axes. For this, we need to define the aesthetic characteristics of our plot.\nSince our goal is to recreate the graph we saw in the beginning of this chapter, which showed the relationship between GDP per capita (gdpPerCap) and life expectancy (lifeExp), we’ll supply these variables to the x and y arguments inside the aes() function.\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp))\n\n\n\n\nNow we have a not-so-blank plot. We can see instead an x-axis, as specified, showing gdpPerCap, and a y-axis, showing lifeExp. But where are our data?\n\n\n4.5.2 Specifying the Type of Plot\nIn order to add data, we have to tell ggplot exactly what type of plot we’d like to create. We could produce a scatterplot, for example, which will cause the data to appear as points, or we could create a line graph, which will connect points into lines. There are other options, of course, but these seem like the most logical choices for this plot.\nIn ggplot(), the different types of plots are called geoms and we can add them as a layer to our base plot by using the + operator followed by the geom_ function that corresponds to the type of plot we want to see. If we wanted to see a line plot, for instance, we would use geom_line(). We want to see a scatterplot, so we’ll use the geom_point() function. Let’s see how the scatterplot looks:\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp)) +\n  geom_point()\n\n\n\n\nWe now have a plot which shows us each country-year as a point. The x-value is the GDP per capita of a country and the y-value is life expectancy at birth, a measure of typical longevity. Notice, we didn’t need to supply an argument to geom_point() nor did we have to tell ggplot() anything other than the mapping of x and y (and, of course, the initial source of data, gapminder, via the pipe operator).\nggplot objects are unique in that we can add additional layers by using the + operator to join them to the base plot and each other. Just like with the pipe operator, however, we need to make sure that the + appears at the end of each intermediate line and not at the beginning of a line. Be on the lookout for these subtle syntax errors:\n# This will not produce a plot with points, \n# because the + operator is in the wrong spot.\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp)) \n  + geom_point()\n  \n# This will produce a plot with points.\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp)) +\n  geom_point()\n\n\n4.5.3 Adding a Smoother\nCan we add more layers to our plot? You bet. We can, for instance, add a line of best fit on top of our points with a geom_smooth() function:\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp)) +\n  geom_point() + \n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nThe output warning here tells us that geom_smooth() used a default argument and formula to calculate the line of best fit.8\n\n\n4.5.4 Mapping More Aesthetics\nWhat else can we do with this visualization? Well, we might want to see if there are other elements that can be changed to reveal more patterns in the data. What if we compared the country-level relationship between gdpPercap and lifeExp by continent, for example? We could create a plot for each continent, showing only the relevant countries for each, or we could keep one plot and modify another element like the color of the data points. In this way, each color would represent the continent a country is located in and the points would be visually differentiated.\nTo do this, we need to modify the aesthetics of our data mapping. We’ll add another argument to the aes() function inside of the ggplot() mapping argument for color. And, of course, since we want to color points by continent, we need to specify color = continent. We’ll skip the line of best fit this time.\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp,\n                       color = continent)) +\n  geom_point()\n\n\n\n\nNow we can see how the relationship between GDP and life expectancy plays out among countries across different continents.\nIt might also be interesting to see how this relationship plays out by population size. Since population size is a continuous quantitative variable, discrete colors may not be a good choice. We could add a color gradient scale (as you might see in a heat map, for example) or we could modify some other element. What about changing the size of the points according to population? Bigger countries could have larger points and smaller countries could have smaller points with a continuum in between. To do this, we need to add a size argument to the aesthetic mapping, this time according to population (pop).\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp,\n                       color = continent,\n                       size = pop)) +\n  geom_point()\n\n\n\n\nYou can now see some trends for some specific countries, including a certain rich and high population country in the Americas. Each time we add an aesthetic,ggplot() makes the necessary change to the plot and then adds a key to interpret each element. We now have scales for population (the size value in our aesthetic mapping) and continent (the color value in our mapping). Another optional aesthetic argument you can use is shape, which changes the points from dots to different symbols (like x’s or o’s). line is another option which changes the type of line for geom_line().\nBecause we have a lot of data points and they’re overlapping, we’re going to skip shape and make it so that the points have some transparency. We can do this by adding an alpha argument to the geom_point() component which controls transparency. alpha takes a value between 0 and 1, where 0 is completely translucent and 1 is not-transparent. We’ll use choose a halfway number, 0.5, but you can play around with the different levels to find your preferred value.\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp,\n                       color = continent,\n                       size = pop)) +\n  geom_point(alpha = 0.5)\n\n\n\n\nWe are getting pretty close to the graph we started the chapter with. At this point, we could add geom_smooth() back to our plot. Take a look at what happens when you do though.\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp,\n                       color = continent,\n                       size = pop)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nThat’s maybe not the result we thought it was going to be. Instead of one smooth curve, as before, we now have a different colored curve for each of the continents. We can also see in the key on the right-hand side that population size is affecting the width of the lines as well.\nOne thing to know about ggplot2 is that each item added to the ggplot() object inherits ggplot()’s aesthetics. So because we defined color by continent and size by population in ggplot()’s mapping argument, geom_point() and geom_smooth() are also also colored by continent and sized by population.\nIf we want to instead ensure that the color and size arguments only affect geom_point(), we need to move those aesthetics to geom_point()’s own aesthetic mapping. See below:\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp)) +\n  geom_point(mapping = aes(color = continent,\n                       size = pop),\n             alpha = 0.5) +\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\ngeom_point()’s mapping accepts the same form of argument as ggplot(). Let’s remove geom_smooth() again anyways, since it doesn’t seem particularly helpful and the plot looks better without it. We can return the color and size arguments to ggplot() or we can leave them as is. Just a few more changes left before we get to a finished product.\n\n\n4.5.5 Changing Scales\nLet’s change the x-axis scale to a logarithmic scale, since the data appears to follow a logarithmic form. Scales can be changed by adding functions from the scale_ family to our plot. Like geom_, there are a number of different options depending on the need. In this case, we want a logarithmic scale for our x-axis in base 10, so we’ll use scale_x_log10().\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp,\n                       size = pop,\n                       color = continent)) +\n  geom_point(alpha = 0.5) +\n  scale_x_log10()\n\n\n\n\nNow we can see the relationship between GDP per capita and life expectancy more clearly. We don’t always have to change the scale of our x- and y-axes, but in this case, the distribution of our x-values calls for it.9 If you don’t add a scale_ function, ggplot2 will simply use the default. We don’t need a scale transformation for our y-axis here, so we’ll skip adding a scale_y_ function and let ggplot2 use the default.\nNote, that there is a big difference between the scale of our axes (the numeric distance between positions along the axis) and our axis labels (how we write each value). Just because the numbers on the axis are written in a strange format doesn’t necessarily mean we will need to change the scale. We may just need to re-write the labels. As you can see, our x-axis labels are still written in an unhelpful format (scientific notation).\n\n\n4.5.6 Changing Scale Labels\nChanging the labels for axes and other scales can be a pain. Fortunately, there is a very helpful package we can use called scales.\nYou should already have a copy of scales installed and you can load it via library(). Another way to access it’s functions is to use the name of the package followed by :: and the name of the desired function. We used this same method in the previous chapter for knitr::kable().\nFor the scale on the x-axis, which corresponds to a variable in U.S. dollars, we’ll use the function scales::label_currency().10 We’ll add this helper function to the labels = argument of our scale_ function in the example below. Other useful scales functions include scales::comma and scales::percent - neither of which require parentheses at the end, unlike label_currency().\nSince we also want to fix the label for the size function, we’ll also add a scale_ function for our size aesthetic (in a separate object) and then set the labels argument to use commas. See below for both steps put together:\n\nlibrary(hrbrthemes) # A theme used for graphs\n# Source: https://youtu.be/04GFB33lUJE?feature=shared&t=2335\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp,\n                       size = pop,\n                       color = continent)) +\n  geom_point(alpha = 0.5) + \n  scale_x_log10(labels = scales::label_currency()) +\n  scale_size(labels = scales::comma)\n\n\n\n\nOur scale labels have been fixed and are much easier to read.\n\n\n4.5.7 Adding Titles\nTo change the titles of different elements, we can add a labs() function to the end of our object. The labs() function will set titles for each part of the plot according to the values given to a set of corresponding arguments.\nIn the code below, you can see that we’ve changed the title for the x and y axes, the size key (“Population”), the color key (“Continent”), the overall title of the graph (“Economic Growth and Life Expectancy”), and then added a caption at the bottom.\n\nlibrary(scales)     # Used for the dollar labels\nlibrary(hrbrthemes) # A theme used for graphs\n# Source: https://youtu.be/04GFB33lUJE?feature=shared&t=2335\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp,\n                       size = pop,\n                       color = continent)) +\n  geom_point(alpha = 0.5) + \n  scale_x_log10(labels = scales::label_currency()) +\n  scale_size(labels = scales::comma) +\n  labs(x = \"GDP Per Capita (log scale)\",\n       y = \"Life Expectancy in Years\",\n       size = \"Population\",\n       color = \"Continent\",\n       title = \"Economic Growth and Life Expectancy\",\n       caption = \" Source: Gapminder \\n Note: Observations are country-years.\")\n\n\n\n\nAt this point, we have a good looking graph and could call it a day. As you will discover though, there are endless opportunities for customization with ggplot2. It’s the reason why ggplot2 graphics can be made to look so good.\n\n\n4.5.8 Adding a Theme\nThemes are customizable sets of aesthetic characteristics that change things like font types and sizes, the alignment of different elements, and the presence of gridlines. You can adjust many of these things by adding a theme() function to the end of your plot and playing around with the different available arguments.\nAlternatively, you can use a theme that someone else has created by installing their package and using the related function. This is often ideal, because you can then find a theme that matches your general preferences and tweak minor elements as needed by overlaying another theme() layer. Playing around with theme settings on your own can be a time consuming affair and in general, isn’t recommend for the personal graphs you use for analytic purposes.\nAmong pre-packaged themes, ggthemes, for example, is a popular package with themes that mimic the styles used in The Economist (theme_economist()), for example, and the Wall Street Journal (theme_wsj()). You can see some more of the styles available in ggthemes here. The theme I used for the graph at the start of this chapter is called theme_ipsum_rc() which comes from the hrbrthemes package. Remember, if you use a theme from a package, you need to first download the package and then load the library (or access the specific function using ::). Some custom themes, like ipsum, also require you to install and register new fonts in R, which can be a pain.\nIf you’d like to avoid the trouble of installing extra packages, you can also use some of the default themes provided in ggplot2, many of which are also quite nice. Adding theme_bw() from ggplot2 to the plot from the previous example, for instance, does this:\n\nlibrary(scales)     # Used for the dollar labels\nlibrary(hrbrthemes) # A theme used for graphs\n# Source: https://youtu.be/04GFB33lUJE?feature=shared&t=2335\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp,\n                       size = pop,\n                       color = continent)) +\n  geom_point(alpha = 0.5) + \n  scale_x_log10(labels = scales::label_currency()) +\n  scale_size(labels = scales::comma) +\n  labs(x = \"GDP Per Capita (log scale)\",\n       y = \"Life Expectancy in Years\",\n       size = \"Population\",\n       color = \"Continent\",\n       title = \"Economic Growth and Life Expectancy\",\n       caption = \" Source: Gapminder \\n Note: Observations are country-years.\") +\n  theme_bw()\n\n\n\n\nYou can see that it has added a border to the plot and removed the gray background from both the plot and the scales. Try using theme_minimal(), theme_classic(), and theme_void() to see how they change the aesthetics instead."
  },
  {
    "objectID": "visualizing-with-ggplot.html#the-final-product",
    "href": "visualizing-with-ggplot.html#the-final-product",
    "title": "4  Visualizing with ggplot2",
    "section": "4.6 The Final Product",
    "text": "4.6 The Final Product\nTo return to the final product, I’ll use theme_ipsum_rc() from hrbrthemes. I’ll also replace the size_scale argument with a more complicated set of functions that makes it even easier to read.\n\nlibrary(hrbrthemes) # A theme used for graphs\n\ngapminder %&gt;%\n  ggplot(mapping = aes(x = gdpPercap, \n                       y = lifeExp,\n                       size = pop,\n                       color = continent)) +\n  geom_point(alpha = 0.5) + \n  scale_x_log10(labels = label_currency()) +\n  scale_size(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(x = \"GDP Per Capita (log scale)\",\n       y = \"Life Expectancy in Years\",\n       size = \"Population\",\n       color = \"Continent\",\n       title = \"Economic Growth and Life Expectancy\",\n       caption = \" Source: Gapminder \\n Note: Observations are country-years.\") +\n  theme_ipsum_rc()\n\n\n\n\nWhichever plot you choose to use as your final plot, you can save it by clicking on the “Plots” tab in the lower right-hand corner of your R Studio window followed by export. We’ll discuss better ways of doing this later on."
  },
  {
    "objectID": "visualizing-with-ggplot.html#other-plots",
    "href": "visualizing-with-ggplot.html#other-plots",
    "title": "4  Visualizing with ggplot2",
    "section": "4.7 Other Plots",
    "text": "4.7 Other Plots\nWe’ve so far only covered one type of plot, a scatterplot. It won’t surprise you to hear that there are many other types of plots that we can create using ggplot2. The good news is that the structure and components of plots are generally consistent across types and that once you start creating plots, you can always re-use the code.\nA quick example of a line chart using the gapminder data is shown below. Note, we’ve made a few changes. We first filtered the data for a small subset of countries so that we can our graph won’t be swamped by too many countries. Then we used geom_line() as our geom_ instead of geom_point(). Perhaps most importantly, we’ve set color to represent each country in order to ensure that our data is mapped to the appropriate unit of observation.\n\nmy_countries = c('France', 'United Kingdom', 'Italy')\n\ngapminder %&gt;%\n  filter(country %in% my_countries) %&gt;%\n  ggplot(aes(x = year, \n             y = pop, \n             color = country)) +\n  geom_line()\n\n\n\n\nTry setting color = continent in the example above and see what happens. You get a bit of a mess. ggplot2 doesn’t naturally understand the correct unit of observation, so specifying continent as color leads it to believe that it needs connect the data points according to the continent for each year and across years. Since France, Italy, and the U.K. are in the same continent, it draws a line connecting each of the three data points inside each year and then connects them across years, leading to a jagged, meaningless graph.\nHere’s a slightly more polished looking version of the initial line graph with some aesthetic and label changes. We can easily change the countries used and other features like the size of geom_line(). Perhaps confusingly, geom_line() can also take a size argument outside of the mapping argument. Note also that you may wish to change the font family in the graphic below to something like ‘Arial’, since you may not have ‘Roboto Condensed’ installed on your computer.\n\nmy_countries = c('France', 'United Kingdom', 'Italy')\n\ngapminder %&gt;%\n  filter(country %in% my_countries) %&gt;%\n  ggplot(aes(x = year, \n             y = pop, \n             color = country)) +\n  geom_line(size = 2) +  \n  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) + \n  labs(x=\"Year\",\n       y = \"Population\",\n       color = \"Country\",\n       title = \"Population Growth in Europe\",\n       caption = \"Source: Gapminder\") + \n  theme_bw() + \n  theme(text = element_text(size = 14, family = \"Roboto Condensed\"),\n                     plot.title = element_text(size = 20, face = \"bold\"),\n                     axis.title.x = element_text(hjust=1), \n                     axis.title.y = element_text(hjust=1))\n\n\n\n\nLast, but not least, we have a bar chart. Here again we’ve filtered for some countries. We’ve then filtered for a specific year, removed color (which works slightly differently for bar charts), and have added the geom_col() geom to specify that it is a bar chart we are making.\n\nmy_countries = c('France', 'United Kingdom', 'Italy', \"Germany\", \"Spain\")\n\ngapminder %&gt;%\n  filter(country %in% my_countries) %&gt;%\n  filter(year == 2007) %&gt;%\n  ggplot(mapping = aes(x = country, \n                       y = pop)) +  \n  geom_col()\n\n\n\n\nWe will work through other examples of visualizations, such as the map below, and the quirks of how they work in future chapters."
  },
  {
    "objectID": "visualizing-with-ggplot.html#summary",
    "href": "visualizing-with-ggplot.html#summary",
    "title": "4  Visualizing with ggplot2",
    "section": "4.8 Summary",
    "text": "4.8 Summary\nIn this chapter, we’ve reviewed some of the measures we might use to describe data, discussed some general principles for producing good data visualizations, and learned how to create and modify some basic plots in ggplot2.\nYou will likely need to read this chapter and reference the code more than once. ggplot2’s structure is not very intuitive to new users. The more you use it, however, and get a feel for how the different plot elements map to the various objects and arguments, the more control you will have over the visualizations you produce.\nSo keep practicing and save your work, adding comments so that you can remember what you were doing. Go back to some of the examples used here and play around with the different arguments. Try to change the plot types. Use different scales. See if you can make something interesting. As you inevitably get errors, try to make a mental note of what works and what doesn’t. Eventually, you’ll have generated a stockpile of code that you can re-use and adjust to create the right visualizations whenever you need them."
  },
  {
    "objectID": "visualizing-with-ggplot.html#exercises",
    "href": "visualizing-with-ggplot.html#exercises",
    "title": "4  Visualizing with ggplot2",
    "section": "4.9 Exercises",
    "text": "4.9 Exercises\nHere are a few exercises to complete either in-class or on your own for homework.\n\nUse the Gapminder data to produce a line graph showing growth in GDP per capita for the United Kingdom, France and Italy.\nDo the same for life expectancy using three other countries of your choice.\nProduce a scatterplot which shows the relationship between GDP per capita and life expectancy for all countries in 2007. Produce another which shows the relationship for 1952 and compare the two.\nProduce a bar chart for life expectancy among countries in Oceania in 2007.\n\n\n\n\n\nHealy, Kieran. 2019. Data Visualization: A Practical Introduction. Princeton: Princeton University Press. socviz.co."
  },
  {
    "objectID": "visualizing-with-ggplot.html#footnotes",
    "href": "visualizing-with-ggplot.html#footnotes",
    "title": "4  Visualizing with ggplot2",
    "section": "",
    "text": "I have neither trophies nor an office, but let’s not let that spoil things.↩︎\nR.I.P. ggplot1 (2006-2008)↩︎\nCredit for this visualization and the series of examples derived from it belong to Healy (2019).↩︎\nThe formula for the sample variance is: \\(S^2={{\\sum{({x_i - \\overline{x}})^2 }} \\over{n-1}}\\)↩︎\nThe formula for the sample standard deviation is: \\(S={\\sqrt{{\\sum{({x_i - \\overline{x}})^2 }} \\over{n-1}}}\\)↩︎\nFor an even more extreme example, see Alberto Cairo’s Datasaurus Dozen, all of which have approximately the same correlation and summary statistics.↩︎\nThis problem is particularly common in maps, as illustrated in this blog post about density maps.↩︎\n‘gam’ stands for general additive model and is one method of adding a line of best fit. ‘lm’, or linear model, is another best fit method.↩︎\nGDP per capita is not normally distributed hence the need for a log-transformation here. The decision on whether to transform an axis or not is a statistical matter, which we won’t go into here.↩︎\nThe default currency for label_currency() is U.S. dollars.↩︎"
  },
  {
    "objectID": "homework-1.html",
    "href": "homework-1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Due Date: Tuesday, 13 February by 23:59:59\nSubmission Instructions: Submit your completed R script file to Moodle.\nThis homework will be relatively short and straight-forward. The goal is to ease you into R now so that you are ready to complete some of the more complex data analysis that will take place later.\nQuestion #1:\nCreate an R script and save it with an appropriate name. Add a header to your R script file in the format below.\n\n# Name: [first_name] [last_name]\n# Date: [date]\n# Description: [brief description of the file] \n\n# Question 2:\n\nQuestion #2:\nIn your R script file, load the tidyverse package. Show the code used.\nQuestion #3:\nCreate a vector with the following set of numbers: \\({30, 60, 90, 120, 150}\\). Perform the following operations, showing the code used for each.\nPart A: Multiply the vector by 2. In a brief comment, tell me what the result was.\nPart B: Take the vector and divide it by 3. Tell me what the result was in a brief comment.\nPart C: Multiply the vector by itself. Tell me what the result was in a brief comment.\nPart D: Return the third element of the vector.\nPart E: Replace the second element of the vector with a missing value (NA).\nPart F: Sum the vector, excluding the missing value. In a comment, write the answer.\nQuestion #4:\nUsing the socviz package (see section 2.3 of the course textbook), load the election dataset into a new object called elec. Complete the following tasks, showing the code used for each.\nPart A: Find the total popular vote received by Gary Johnson using the johnson_vote variable.\nPart B: Find the total popular vote received by ‘Other’ candidates using the other_vote variable.\nPart C: In a comment answer the following question: who received more votes, Gary Johnson or “other” candidates? By how much?\nPart D: Use the sum() function on the state variable. In a brief comment, explain why this didn’t work and what the error message is telling you."
  },
  {
    "objectID": "homework-2.html#footnotes",
    "href": "homework-2.html#footnotes",
    "title": "Homework 2",
    "section": "",
    "text": "A brief technical note: although the GSS is a nationally representative survey of U.S. adults, we are using the term “respondents” throughout this assignment rather than “U.S. adults.”\nThe reason for this is that estimating population-level statistics (like the proportion of U.S. adults who are married) requires using survey weights, which is a slightly more complicated procedure that takes into account the survey design. Survey weights are used to help ensure that the statistics being reported from survey data accurately reflect the population.\nIn practice, the numbers you will obtain in this assignment are very close to the best estimates possible for U.S. adults, but since they’re not exactly precise (i.e., they don’t take into account the survey weights), it’s more accurate to refer to your results as relating to the respondents of the GSS rather than all U.S. adults. The differences between the properly weighted results and the results you obtain in this assignment are within 1%, however.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Healy, Kieran. 2019. Data Visualization: A Practical\nIntroduction. Princeton: Princeton University Press. socviz.co."
  }
]