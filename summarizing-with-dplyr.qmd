# Summarizing Data with `dplyr`

In the previous chapter, you learned how to load data from a package, how to access a column from a tibble using the subset operator `$`, and how to use basic functions to answer questions like: what was the total number of votes cast in the 2016 U.S. presidential election?

We've had a couple strokes of luck so far. Our data has been nice and tidy and our questions haven't really required us to poke around in our data to find the answers we are interested in. This brings us to *data wrangling* - the art and science of manipulating, distilling, or cajoling data into a format that allows you to find the answers you are seeking.

For this lesson, we are going to continue to maintain the illusion of neat and tidy data and focus on learning the tools necessary to dig deeper into a data set: in particular, `dplyr` and the **pipe operator**. In future lessons, our luck will run out and we will be confronted with the harsh reality of unseemly data.[^04-using-the-tidyverse-1]

[^04-using-the-tidyverse-1]: Sadly, almost all data you encounter out in the wild will be very unseemly for one reason or another. But, maybe after taking this course and ascending the ranks of government/business/academia, you too will become an evangelical for orderly data and help to make the world a tidier place.

## Basic Description with Base `R`

Let's use an example to get us started. Last class, you toyed around with the 2016 U.S. presidential election data from the `socviz` package, a helpful collection of data sets and other goodies developed by Kieran Healy.[^04-using-the-tidyverse-2]

[^04-using-the-tidyverse-2]: The `socviz` package serves as an accompaniment to Healy's textbook, *Data Visualization*, which is highly recommended.

We'll use another data set from the same package in a moment, but, for now, let's return to the `election` data. We're also going to re-load our new best friend, the *tidyverse* package.

```{r, echo = TRUE, results='hide'}
library(socviz)
library(tidyverse)
```

Libraries loaded. Remember, once you have the packages installed, you don't need to do it again. So, don't include `install.packages()` in your scripts going forward.[^04-using-the-tidyverse-3]

[^04-using-the-tidyverse-3]: Anytime you install packages, do it directly in the console. If someone needs to run your code, they should see the `library()` calls in the beginning of your code after the header and will know whether they need to install additional packages or not. RStudio also has a helpful auto-prompt feature that will inform you of missing packages.

    Instead of the `library()` function, you can also use the `require()` function, which has the benefit of both loading packages if you have them already installed and installing them if you don't.

We'll load the data into an object in our environment. This time, we'll use a slightly shorter name for the tibble to spare ourselves some future misery. A longer name means more to retype later.

```{r}
elec_2016 <- election
```

Just like last time, we can do basic calculations on columns using the subset operator and column name. Let's add a few new functions to our repertoire for good measure:

```{r}
# table() gives a contingency table for character variables.
# Here's the number of states (plus D.C.) won by each candidate.
table(elec_2016$winner)
```

```{r}
# Wrapping prop.table() around a contingency table gives relative frequencies.
# i.e., Hillary Clinton won 41.2% (21/51) of states (plus Washington D.C.).
prop.table(table(elec_2016$winner))
```

```{r}
# summary() gives us a nice 5-number summary for numeric variables.
# Here we see the min, max, median, mean, and quartiles for the pop. vote margin.
summary(elec_2016$vote_margin)
```

But, what if we want to do something more specific?

What if we really want to know how much of the popular vote third-party Libertarian candidate Gary Johnson won across the different regions of the United States? Here we need special functions from `dplyr` and the pipe operator.

```{r}
# An illustrative example - no need to try this yet
elec_2016 %>%
  group_by(census) %>%
  summarize(total = sum(johnson_vote))
```

We'll learn how to create frequency tables like this and more in a moment.

## The Pipe Operator

![](images/ceci_pipe.png)

The **pipe operator** is a handy tool indeed. It is a specialized operator that comes from the `magrittr` package, which itself is contained in the tidyverse.

It looks like this: `%>%`. But, it can also look like this: `|>`.

There isn't much of a difference between the two, so you can use whichever you prefer as long as you are consistent.[^04-using-the-tidyverse-4]

[^04-using-the-tidyverse-4]: For more on the differences between the two pipe operators, see here: [https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe](https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/#){.uri}

The pipe operator has a straightforward function: it allows you to combine a series of steps into a single command. And, it does this in a way that makes your code legible. Whenever you see the pipe operator, you should read it as though it is saying, "And then \[do this\]."

So in the previous example provided, you might read it as:

```{r, results='hide'}
elec_2016 %>%                            # Take the election data AND THEN
  group_by(census) %>%                   # group it by census region AND THEN
  summarize(total = sum(johnson_vote))   # sum up the Johnson vote.
```

Note a couple of things here:

1.  The pipe operator always goes at the end of each line, followed by a new line

2.  The pipe operator never goes at the end of the command

The first is a convention to make the code more readable and the second is a requirement. If you leave a pipe operator at the end of your statement, `R` will search for the missing code and then give you an unfriendly error when you try to run more code. Don't leave a pipe operator hanging.

## Functions from `dplyr`

`dplyr` (pronounced dee-ply-R) is a set of tools for working with tabular data. It's one of the packages in tidyverse (along with `ggplot2`, `tidyr`, `tibble`, `readr`, and a few others), so you don't have to load it separately.

`dplyr` has a handful of special functions:

-   `group_by()`, which groups data together at some desired level (e.g., states by census region)

-   `filter()`, which gives us the rows corresponding to the criteria entered as an argument

-   `select()`, which selects columns from the original data

-   `summarize()` or `summarise()`, which performs calculations[^04-using-the-tidyverse-5]

-   `mutate()`, which creates new columns (or variables)

-   `arrange()`, which sorts the row order by column values

[^04-using-the-tidyverse-5]: `summarize()` and `summarise()` are the same function, just two different spellings, the choice of which depends on who you've learned English from.

## Glimpsing GSS Data

Let's load another data set from `socviz`. This one is called `gss_sm` and contains a nice, clean extract from the 2016 General Social Survey.

```{r}
gss <- gss_sm
```

The [General Social Survey](https://gss.norc.org/) is a nationally representative biennial survey of U.S. adults on sociological topics produced by the National Opinion Research Center (NORC) at the University of Chicago since 1972.

Take a quick look at the data. You can use `glimpse()`, another `dplyr` function, to get a sense of what's inside and you can inspect it visually using `view()`. Typing in `?gss_sm` (the original name of the data set from the package) will tell you what variables the data contains.[^04-using-the-tidyverse-6]

[^04-using-the-tidyverse-6]: You won't always be able to get documentation on a data set by using the help function, unfortunately. But, in this case, it works because `socviz` comes with documentation that was downloaded when you installed the package. Note that you must refer to the data in your help query by it's original name (`?gss_sm` not `?gss`).

```{r, results='hide'}
view(gss)
glimpse(gss)
```

There's a wealth of data in here. You may have also noticed that the data here is at the *individual-level*. Each row represents an individual respondent (identified by the `id` variable) and each column consists of a variable (in this case, a coded response to a survey question).

If we click on our data in the environment pane, we can see that the first data row corresponds to respondent #1 who is 47 years old and has 3 children:

![](images/GSS_Respondent-1.png)

## Selecting Columns

There are a lot of variables, 32 of them, in fact. Maybe we want to narrow in and look at just a few of them, like: `id`, `sex`, and `religion`. We can use the `select()` function to do this.

```{r}
gss %>%                             # Take the GSS data AND THEN
  select(id, sex, religion)         # take just the ID, sex, and religion columns.
```

In the code above, we told `R` that we wanted to take the GSS data and then only the `id`, `sex`, and `religion` variables. The select function output a new tibble containing only those three variables that were entered as arguments. The number of rows or observations, 2,867, is the same as in the original data.

We can now save a copy of this new tibble by assigning it to a new object. Let's call this new object `gender_relig`.

```{r}
gender_relig <- gss %>%
  select(id, sex, religion)
```

Now we have a new object containing our new tibble. If you inspect this new tibble and then decide that you don't need or want it anymore, you can always get rid of it using the `rm()` function.[^04-using-the-tidyverse-7]

[^04-using-the-tidyverse-7]: Using the `rm()` function can help keep your environment a bit more orderly, but it isn't always necessary since your environment will be cleared out each time you close RStudio anyways.

```{r, results='hide'}
view(gender_relig)
rm(gender_relig)
```

## Grouping and Summarizing

Let's say we want to get a table which shows the number of respondents by religious affiliation. There are other ways of doing this, but we're going to use `dplyr` and the pipe operator.

To do this, we first have to tell `R` how we would like to group the data. Grouping doesn't visibly change the data, but it prepares `R` to interpret our next commands according to the groups we specify. We're going to group by the `religion` variable which contains the respondent's religious affiliation.

```{r}
gss %>%
  group_by(religion)
```

As you can see, our data doesn't appear to have changed in the output above. We still have 32 variables and 2,867 observations. But, we do actually get a helpful note at the top our output that says, `Groups: religion[6]`. Our observations have been successfully grouped according to the six religious affiliations in our data.

Next, we have to add another line to our pipe function which specifies how we want to `summarize()` the groups. We want it to count up our rows, so we'll use the `n()` function. The `n()` function just counts the number of rows in a data frame.[^04-using-the-tidyverse-8] We have to tell `summarize()` where we want to store these values, so we'll put them in a new variable called `total`.

[^04-using-the-tidyverse-8]: There are other options for counting the number of rows, like the `count()` or `tally()` functions, but I won't use them here.

```{r}
gss %>%
  group_by(religion) %>%      # Group by religion
  summarize(total = n())      # Create a total by counting the rows
```

As you can see, we provided `summarize()` with a new column name, `total`, and a measurement, `n()`. Now, we have the total number of respondents for each group (religious affiliation). The pipe operator allowed us to combine the `group()` and `summarize()` functions together in sequence so that we got the analysis we wanted..

If we want, we can save a copy of our new tibble in another object, as in the command below. The original data object in our environment (i.e.., `gss`) will always be untouched unless we intentionally re-write it (i.e., `gss <- gss %>% ...`).

```{r}
relig <- gss %>%
  group_by(religion) %>%
  summarize(total = n())
```

Another quick example. Let's say we want to see the count of our 2016 GSS respondents by sex:

```{r}
gss %>%
  group_by(sex) %>%
  summarize(total = n())
```

In this example, we took the GSS data *and then* grouped it by `sex` *and then* summarized it by creating a `total` which contains a count of the number of rows.

In this case, because we have tidy data (more on this in future lessons), the number of rows corresponds to the number of respondents who took the 2016 GSS. We can see that 1,276 of our respondents were male and 1,591 were female.

### Grouping by Two Variables

We can also create the equivalent of what is called a two-way contingency table by grouping with two variables at the same time. We can use this to find religious affiliation by sex, for example:

```{r}
gss %>%
  group_by(religion, sex) %>%
  summarize(total = n())
```

In the table above, we can now identify the number of protestants who are male and the number of protestants who are female.

### The Order of `group()` arguments

It is worth noting that the ordering of groups as arguments in the `group()` function sometimes matters (i.e., `group_by(religion, sex)` as opposed to `group_by(sex, religion)`.

Because religion came first in our argument order, our results show us the number of protestants who are male and the number of protestants who are female. But we could have very easily shown the number of males who are protestant and the number of females who are protestant.

For a count, it does not matter. The number of protestants who are male is the same as the number of males who are protestant. But, when we start looking at relative frequencies and percentages, the order does matter. You'll get a sense for this in a moment.

## Calculating with `mutate()`

Is there an equivalent proportion of males and females among protestants in the GSS? Let's add a relative frequency column to find out.

```{r}
gss %>%
  group_by(religion, sex) %>%
  summarize(total = n()) %>%
  mutate(freq = total / sum(total),
         pct = round((freq*100), 1))
```

Notice, we used the same code as before here, but now we've added another step, a `mutate()` function to create two new columns, `freq` (relative frequency) and `pct` (percentage).

We previously calculated the `total` or the number of observations for each sub-group (e.g., protestants who are males, protestants who are females, etc.). The `mutate()` function takes the `total` we calculated in the previous step and uses it to calculate first the relative frequency and then the percentage for each sub-group.

To calculate the relative frequency, we used `freq = total / sum(total)` or in plain English "create a new value called `freq` and then calculate this value by taking the number of observations for each sub-group (`total`) and then dividing it by the sum of the totals for all sub-groups (`sum(total)`)."

For the religious group protestant, we have two sub-groups, male and female, and so the frequency for males protestants is calculated as `559 / (559 + 812)`, which equals `0.408` , or exactly what you see in the first row in the frequency column in our new tibble. Similarly, the frequency for female protestants would be `812 / (559 + 812)` or `0.592` or what you see in the frequency column in the second row of our new tibble.

What about the percentage or `pct`? In the second argument of our `mutate()` function, we told `R` to take the `freq` we calculated in the previous step, multiply it by 100 (to make it a percentage), and then round it to the first decimal place using the `round()` function. `0.408`, the relative frequency of male protestants, therefore becomes 40.8%.

As you can see, calculating relative frequencies and percentages using `dplyr` and the pipe function can be a bit of a beast. The good news is that the general form is always the same and so you'll be able to re-use the code often.

## How `R` Reads Functions

In the previous examples, you may have noticed a bunch of *nested functions*, which is when a function is used as an argument inside another functions, e.g., `summarize(total = n())`. It's worth pausing for a moment to think about how `R` reads code, since you will be using these types of constructions quite often.

Functions are always read inside out, so a nested function will always evaluate the inner-most function first. Pipe operations, on the other hand, are always read from left-to-right or top-to-bottom (if you're breaking up your code using new lines, as you should be). The two commands below evaluate in the same way, but `R` reads them in a slightly different ordering.

```{r}
# Inside-out evaluation
sum(c(1,2,3))               # A vector, {1,2,3} is created first AND THEN summed

# Left-to-right/top-to-bottom (sequential) evaluation
c(1,2,3) %>%                # A vector is created AND THEN
  sum()                     # it is summed
```

## Filtering

Back to the data. What if we only wanted to see the protestant results for our previous examples? We can use a `filter()` function.

```{r}
gss %>%
  group_by(religion, sex) %>%
  summarize(total = n()) %>%
  mutate(freq = total / sum(total),
         pct = round((freq*100), 1)) %>%
  filter(religion == "Protestant")
```

In a filter function, you use logical and comparison operators (see the slides from Session 3 if you'd like a refresher) to define the criteria for your new tibble. In this case, we want only the observations for which the `religion` variable is equal to "Protestant".

`R` is case-sensitive and so if the values in your data are "protestant", for example, you won't see those results in the tibble output here.

Here's another example using `filter()`. Usually, you will want to use the `filter()` function at the beginning of your query. This time, I'm only interested in religious affiliation among holders of graduate degrees.

```{r}
gss %>%
  filter(degree == 'Graduate') %>%
  group_by(religion) %>%
  summarize(total = n()) %>%
  mutate(freq = total / sum(total),
         pct = round((freq*100), 1))
```

Now, we see that 39.6% of graduate-degree holding respondents were protestant and 25.8% had no religious affiliation. Later on, we'll learn how to turn this sort of thing into a nice graph.

```{r}
# What happens if I use a lower-case 'g' in 'Graduate' instead?
gss %>%
  filter(degree == 'graduate') %>%
  group_by(religion) %>%
  summarize(total = n()) %>%
  mutate(freq = total / sum(total),
         pct = round((freq*100), 1))
```

## Conditional Filtering

What if we want to filter our respondents for multiple degree types? We want to see in our table of religious affiliation, for example, only people who have a bachelor's degree **or** a graduate degree.

For these types of queries, we can use other logical operators in our `filter()` criteria. Here, specifically, we'll use `|` which stands for '**or**'.

```{r}
gss %>%
  filter(degree == 'Graduate' | degree == 'Bachelor') %>%
  group_by(religion) %>%
  summarize(total = n()) %>%
  mutate(freq = total / sum(total),
         pct = round((freq*100), 1))
```

Now our results include only college graduates and graduate degree holders. If we want to see them broken out separately after we have filtered, all we need to do is change `group_by(religion)` to `group_by(religion, degree)`.

What if we want to filter our observations for all individuals with less than a bachelor's degree? We can create a vector with our specific criteria and then use it in our filter argument. Look at this:

```{r}
filter_criteria <- c('Lt High School', 'High School', 'Junior College')

gss %>%
  filter(degree %in% filter_criteria) %>%
  group_by(religion, degree) %>%
  summarize(total = n()) %>%
  mutate(freq = total / sum(total),
         pct = round((freq*100), 1))
```

We've first created a vector, called `filter_criteria`, with all of the degree-levels we want to include in our data (we've left out 'Graduate' and 'Bachelor'). Then, we've changed the filter criteria to say, "Take all respondents who have a degree listed in our vector, `filter_criteria`." In code, we write this as: `filter(degree %in% filter_criteria)`.

### The `%in%` Operator

`%in%` is a special logical operator that checks to see whether the values you are specifying are contained in an object. If the value is contained in the object, your computer will return `TRUE` and if not, it will return `FALSE`. This is especially useful for `filter()` since `filter()` selects rows based on whether they meet a criteria (`TRUE`) or not (`FALSE`).

Here's a simple example of how this operator works in general:

```{r}
1 %in% c(1,2,3,4,5)
```

```{r}
6 %in% c(1,2,3,4,5)
```

## Fancy Tables with `kable()`

If we want to make a summary table look a little bit nicer, we can add the `knitr::kable()` function to the end of our query to produce a more polished looking table.

```{r}
gss %>%
  filter(degree == 'Graduate') %>%
  group_by(religion) %>%
  summarize(total = n()) %>%
  mutate(freq = total / sum(total),
         pct = round((freq*100), 1)) %>%
  knitr::kable()
```

The `::` operator here tells `R` to pull the `kable()` function from the `knitr` package (which is located in the tidyverse). This is useful when there are multiple functions with the same name in different packages.

You can also add additional code to your `kable()` function to customize the look of your table (see [here](https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html) for examples).

## Another Example

What if we want to do something crazy like find all survey respondents who are protestant or catholic, voted for Obama in the 2012 U.S. Presidential election, and have children? And, we'd like to know their breakdown by relative frequency across regions of the U.S.

Here's a brief example:

```{r}
gss %>%
  filter(religion == "Protestant" | religion == "Catholic") %>%
  filter(obama == 1) %>%
  filter(childs > 0) %>%
  group_by(region) %>%
  summarize(total = n()) %>%
  mutate(freq = round(total / sum(total),4),
         pct = round((freq*100), 1))
```

Now, we can rest easy knowing that we can find the percentage of 2012-Obama supporting Protestants and/or Catholics with children who reside in the South Atlantic census region (29.2%).

## Practice Exploring Data

You can see here that the `dplyr` functions provide an enormous amount of flexibility and power. `R`, like other programming languages, is also very sensitive to mistakes in syntax or spelling: a missing comma in a set of function arguments, a hanging pipe operator, a misspelled filter criteria, or an erroneous object name can all cause output errors. Check your code carefully, take a deep breath, and try again. You'll get the hang of it in no time.

Use the remainder of class time today to explore the `gss_sm` data. Try summarizing different variables according to different groupings. Try using other measures like `mean()` or `sd()` to summarize numeric variables (like the number of children).

If you are feeling overwhelmed at the moment - don't despair, we're going to continue practicing these skills throughout the rest of the course.
